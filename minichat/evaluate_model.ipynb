{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0421d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minichat.common import get_base_dir\n",
    "import os\n",
    "import fcntl\n",
    "import urllib.request\n",
    "import tempfile, zipfile\n",
    "import shutil\n",
    "import hashlib\n",
    "import yaml\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea13821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_with_lock(url, filename, postprocess_fn=None):\n",
    "    \"\"\"\n",
    "    Downloads a file from a URL to a local path in the base directory.\n",
    "    Uses a lock file to prevent concurrent downloads among multiple ranks.\n",
    "    \"\"\"\n",
    "    base_dir = get_base_dir()\n",
    "    file_path = os.path.join(base_dir, filename)\n",
    "    lock_path = file_path + \".lock\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        return file_path\n",
    "\n",
    "    with open(lock_path, 'w', encoding='utf-8') as lock_file:\n",
    "\n",
    "        # Only a single rank can acquire this lock\n",
    "        # All other ranks block until it is released\n",
    "        fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n",
    "\n",
    "        # Recheck after acquiring lock (another process may have downloaded it)\n",
    "        if os.path.exists(file_path):\n",
    "            return file_path\n",
    "\n",
    "        # Download the content as bytes\n",
    "        print(f\"Downloading {url}...\")\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            content = response.read() # bytes\n",
    "\n",
    "        # Write to local file\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        print(f\"Downloaded to {file_path}\")\n",
    "\n",
    "        # Run the postprocess function if provided\n",
    "        if postprocess_fn is not None:\n",
    "            postprocess_fn(file_path)\n",
    "\n",
    "    # Clean up the lock file after the lock is released\n",
    "    try:\n",
    "        os.remove(lock_path)\n",
    "    except OSError:\n",
    "        pass  # Ignore if already removed by another process\n",
    "\n",
    "def place_eval_bundle(file_path):\n",
    "    # here file_path is the path to the eval_bundle.zip file\n",
    "    # we need to unzip it and place it in the base directory\n",
    "    base_dir = get_base_dir()\n",
    "    eval_bundle_dir = os.path.join(base_dir, \"eval_bundle\")\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(tmpdir)\n",
    "        extracted_bundle_dir = os.path.join(tmpdir, \"eval_bundle\")\n",
    "        shutil.move(extracted_bundle_dir, eval_bundle_dir)\n",
    "    print(f\"Placed eval_bundle directory at {eval_bundle_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5437a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_BUNDLE_URL = \"https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8ae735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shadeform/minichat/minichat/eval_bundle.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file_with_lock(EVAL_BUNDLE_URL, \"eval_bundle.zip\", postprocess_fn=place_eval_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0062be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = get_base_dir()\n",
    "eval_bundle_dir = os.path.join(base_dir, \"eval_bundle\")\n",
    "config_path = os.path.join(eval_bundle_dir, \"core.yaml\")\n",
    "data_base_path = os.path.join(eval_bundle_dir, \"eval_data\")\n",
    "eval_meta_data = os.path.join(eval_bundle_dir, \"eval_meta_data.csv\")\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d466c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = config['icl_tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80571b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_baselines = {}\n",
    "with open(eval_meta_data, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        task_name = row['Eval Task']\n",
    "        random_baseline = row['Random baseline']\n",
    "        random_baselines[task_name] = float(random_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d087548",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks[0]  # Example: get the first task\n",
    "\n",
    "label = task['label']\n",
    "task_meta = {\n",
    "    'task_type': task['icl_task_type'],\n",
    "    'dataset_uri': task['dataset_uri'],\n",
    "    'num_fewshot': task['num_fewshot'][0],\n",
    "    'continuation_delimiter': task.get('continuation_delimiter', ' ')\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807c4bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hellaswag_zeroshot',\n",
       " {'task_type': 'multiple_choice',\n",
       "  'dataset_uri': 'language_understanding/hellaswag.jsonl',\n",
       "  'num_fewshot': 0,\n",
       "  'continuation_delimiter': ' '})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, task_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d50845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_base_path, task_meta['dataset_uri'])\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line.strip()) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660aacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "max_per_task = 10\n",
    "\n",
    "shuffle_rng = random.Random(1337)\n",
    "shuffle_rng.shuffle(data)\n",
    "data = data[:max_per_task]\n",
    "\n",
    "\n",
    "correct = torch.zeros(len(data))\n",
    "for i in range(len(data)):\n",
    "    example = data[i]\n",
    "    task_type = task_meta['task_type']\n",
    "    num_fewshot = task_meta['num_fewshot']\n",
    "    continuation_delimiter = task_meta['continuation_delimiter']\n",
    "\n",
    "    fewshot_examples = []\n",
    "    if num_fewshot > 0:\n",
    "        rng = random.Random(42 + i)  # Seed with a combination of a constant and the example index\n",
    "        available_indices = [idx for idx in range(len(data)) if idx != i]\n",
    "        fewshot_indices = rng.sample(available_indices, num_fewshot)\n",
    "        fewshot_examples = [data[idx] for idx in fewshot_indices]         \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4dd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "template_str = \"\"\"\n",
    "{%- for ex in fewshot_examples %}\n",
    "{{ex.query}}{{ continuation_delimiter }}{{ ex.choices[ex.gold] }}\n",
    "\n",
    "{%- endfor %}\n",
    "{{item.query}}{{ continuation_delimiter }}{{choice}}\n",
    "\"\"\".strip() \n",
    "\n",
    "template = Template(template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cc1cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [template.render(\n",
    "    fewshot_examples=fewshot_examples,\n",
    "    item=example,\n",
    "    choice=choice,\n",
    "    continuation_delimiter=continuation_delimiter)\n",
    "    for choice in example['choices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8fe80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minichat.tokenizer import get_tokenizer\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b9f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_length(prompts, direction='left'):\n",
    "    \"\"\"\n",
    "    Finds the common length of tokenized prompts.\n",
    "    direction: 'left' or 'right' - indicates which side to consider for commonality\n",
    "    \"\"\"\n",
    "    tokenized_prompts = [tokenizer.encode(prompt) for prompt in prompts]\n",
    "    if direction == 'left':\n",
    "        min_length = min(len(tokens) for tokens in tokenized_prompts)\n",
    "        common_length = 0\n",
    "        for i in range(min_length):\n",
    "            current_token = tokenized_prompts[0][i]\n",
    "            if all(tokens[i] == current_token for tokens in tokenized_prompts):\n",
    "                common_length += 1\n",
    "            else:\n",
    "                break\n",
    "        return common_length\n",
    "    elif direction == 'right':\n",
    "        min_length = min(len(tokens) for tokens in tokenized_prompts)\n",
    "        common_length = 0\n",
    "        for i in range(1, min_length + 1):\n",
    "            current_token = tokenized_prompts[0][-i]\n",
    "            if all(tokens[-i] == current_token for tokens in tokenized_prompts):\n",
    "                common_length += 1\n",
    "            else:\n",
    "                break\n",
    "        return common_length\n",
    "    else:\n",
    "        raise ValueError(\"Direction must be 'left' or 'right'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e864a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(prompts, prepand=tokenizer.get_bos_token_id())\n",
    "start_indices = find_common_length(prompts, direction='left')\n",
    "end_indices = [len(p) for p in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46021a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14f16e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_sequences(tokens, pad_token_id):\n",
    "    bsz, seq_len = len(tokens), max(len(t) for t in tokens)\n",
    "    input_ids = torch.full((bsz, seq_len), pad_token_id, dtype=torch.long)\n",
    "    for i, x in enumerate(tokens):\n",
    "        input_ids[i, :len(x)] = torch.tensor(x, dtype=torch.long)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test start_sequences\n",
    "vocab_size = 256\n",
    "  \n",
    "tokens = torch.randint(0, vocab_size, (batch_size, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_len = 1024\n",
    "new_tokens, new_start_ids, new_end_ids = [], [], []\n",
    "\n",
    "for t, s, e in zip(tokens, start_indices, end_indices):\n",
    "    if len(t) > max_token_len:\n",
    "        num_to_crop = len(t) - max_token_len\n",
    "        new_tokens.append(t[-max_token_len:])\n",
    "        new_start_ids.append(s-num_to_crop)\n",
    "        new_end_ids.append(e-num_to_crop)\n",
    "    else:\n",
    "        new_tokens.append(t)\n",
    "        new_start_ids.append(s)\n",
    "        new_end_ids.append(e)\n",
    "    \n",
    "tokens, start_ids, end_ids = new_tokens, new_start_ids, new_end_ids\n",
    "\n",
    "pad_token_id = tokenizer.get_bos_token_id()\n",
    "input_ids = \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minichat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
