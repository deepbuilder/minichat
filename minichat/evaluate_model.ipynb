{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0421d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minichat.common import get_base_dir\n",
    "import os\n",
    "import fcntl\n",
    "import urllib.request\n",
    "import tempfile, zipfile\n",
    "import shutil\n",
    "import hashlib\n",
    "import yaml\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea13821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_with_lock(url, filename, postprocess_fn=None):\n",
    "    \"\"\"\n",
    "    Downloads a file from a URL to a local path in the base directory.\n",
    "    Uses a lock file to prevent concurrent downloads among multiple ranks.\n",
    "    \"\"\"\n",
    "    base_dir = get_base_dir()\n",
    "    file_path = os.path.join(base_dir, filename)\n",
    "    lock_path = file_path + \".lock\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        return file_path\n",
    "\n",
    "    with open(lock_path, 'w', encoding='utf-8') as lock_file:\n",
    "\n",
    "        # Only a single rank can acquire this lock\n",
    "        # All other ranks block until it is released\n",
    "        fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n",
    "\n",
    "        # Recheck after acquiring lock (another process may have downloaded it)\n",
    "        if os.path.exists(file_path):\n",
    "            return file_path\n",
    "\n",
    "        # Download the content as bytes\n",
    "        print(f\"Downloading {url}...\")\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            content = response.read() # bytes\n",
    "\n",
    "        # Write to local file\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        print(f\"Downloaded to {file_path}\")\n",
    "\n",
    "        # Run the postprocess function if provided\n",
    "        if postprocess_fn is not None:\n",
    "            postprocess_fn(file_path)\n",
    "\n",
    "    # Clean up the lock file after the lock is released\n",
    "    try:\n",
    "        os.remove(lock_path)\n",
    "    except OSError:\n",
    "        pass  # Ignore if already removed by another process\n",
    "\n",
    "def place_eval_bundle(file_path):\n",
    "    # here file_path is the path to the eval_bundle.zip file\n",
    "    # we need to unzip it and place it in the base directory\n",
    "    base_dir = get_base_dir()\n",
    "    eval_bundle_dir = os.path.join(base_dir, \"eval_bundle\")\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(tmpdir)\n",
    "        extracted_bundle_dir = os.path.join(tmpdir, \"eval_bundle\")\n",
    "        shutil.move(extracted_bundle_dir, eval_bundle_dir)\n",
    "    print(f\"Placed eval_bundle directory at {eval_bundle_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5437a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_BUNDLE_URL = \"https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8ae735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip...\n",
      "Downloaded to /home/shadeform/minichat/minichat/eval_bundle.zip\n",
      "Placed eval_bundle directory at /home/shadeform/minichat/minichat/eval_bundle\n"
     ]
    }
   ],
   "source": [
    "download_file_with_lock(EVAL_BUNDLE_URL, \"eval_bundle.zip\", postprocess_fn=place_eval_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0062be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = get_base_dir()\n",
    "eval_bundle_dir = os.path.join(base_dir, \"eval_bundle\")\n",
    "config_path = os.path.join(eval_bundle_dir, \"core.yaml\")\n",
    "data_base_path = os.path.join(eval_bundle_dir, \"eval_data\")\n",
    "eval_meta_data = os.path.join(eval_bundle_dir, \"eval_meta_data.csv\")\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d466c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = config['icl_tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80571b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_baselines = {}\n",
    "with open(eval_meta_data, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        task_name = row['Eval Task']\n",
    "        random_baseline = row['Random baseline']\n",
    "        random_baselines[task_name] = float(random_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d087548",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks[0]  # Example: get the first task\n",
    "\n",
    "label = task['label']\n",
    "task_meta = {\n",
    "    'task_type': task['icl_task_type'],\n",
    "    'dataset_uri': task['dataset_uri'],\n",
    "    'num_fewshot': task['num_fewshot'][0],\n",
    "    'continuation_delimiter': task.get('continuation_delimiter', ' ')\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807c4bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hellaswag_zeroshot',\n",
       " {'task_type': 'multiple_choice',\n",
       "  'dataset_uri': 'language_understanding/hellaswag.jsonl',\n",
       "  'num_fewshot': 0,\n",
       "  'continuation_delimiter': ' '})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, task_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d50845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_base_path, task_meta['dataset_uri'])\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line.strip()) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660aacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "max_per_task = 10\n",
    "\n",
    "shuffle_rng = random.Random(1337)\n",
    "shuffle_rng.shuffle(data)\n",
    "data = data[:max_per_task]\n",
    "\n",
    "\n",
    "correct = torch.zeros(len(data))\n",
    "for i in range(len(data)):\n",
    "    example = data[i]\n",
    "    task_type = task_meta['task_type']\n",
    "    num_fewshot = task_meta['num_fewshot']\n",
    "    continuation_delimiter = task_meta['continuation_delimiter']\n",
    "\n",
    "    fewshot_examples = []\n",
    "    if num_fewshot > 0:\n",
    "        rng = random.Random(42 + i)  # Seed with a combination of a constant and the example index\n",
    "        available_indices = [idx for idx in range(len(data)) if idx != i]\n",
    "        fewshot_indices = rng.sample(available_indices, num_fewshot)\n",
    "        fewshot_examples = [data[idx] for idx in fewshot_indices]         \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4dd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "template_str = \"\"\"\n",
    "{%- for ex in fewshot_examples %}\n",
    "{{ex.query}}{{ continuation_delimiter }}{{ ex.choices[ex.gold] }}\n",
    "\n",
    "{%- endfor %}\n",
    "{{item.query}}{{ continuation_delimiter }}{{choice}}\n",
    "\"\"\".strip() \n",
    "\n",
    "template = Template(template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cc1cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [template.render(\n",
    "    fewshot_examples=fewshot_examples,\n",
    "    item=example,\n",
    "    choice=choice,\n",
    "    continuation_delimiter=continuation_delimiter)\n",
    "    for choice in example['choices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8fe80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minichat.tokenizer import get_tokenizer\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b9f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_length(prompts, direction='left'):\n",
    "    \"\"\"\n",
    "    Finds the common length of tokenized prompts.\n",
    "    direction: 'left' or 'right' - indicates which side to consider for commonality\n",
    "    \"\"\"\n",
    "    tokenized_prompts = [tokenizer.encode(prompt) for prompt in prompts]\n",
    "    if direction == 'left':\n",
    "        min_length = min(len(tokens) for tokens in tokenized_prompts)\n",
    "        common_length = 0\n",
    "        for i in range(min_length):\n",
    "            current_token = tokenized_prompts[0][i]\n",
    "            if all(tokens[i] == current_token for tokens in tokenized_prompts):\n",
    "                common_length += 1\n",
    "            else:\n",
    "                break\n",
    "        return common_length\n",
    "    elif direction == 'right':\n",
    "        min_length = min(len(tokens) for tokens in tokenized_prompts)\n",
    "        common_length = 0\n",
    "        for i in range(1, min_length + 1):\n",
    "            current_token = tokenized_prompts[0][-i]\n",
    "            if all(tokens[-i] == current_token for tokens in tokenized_prompts):\n",
    "                common_length += 1\n",
    "            else:\n",
    "                break\n",
    "        return common_length\n",
    "    else:\n",
    "        raise ValueError(\"Direction must be 'left' or 'right'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87e864a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(prompts, prepand=tokenizer.get_bos_token_id())\n",
    "start_indices = [find_common_length(prompts, direction='left')]* len(prompts)\n",
    "end_indices = [len(p) for p in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46021a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59, 59, 59, 59]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14f16e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_sequences(tokens, pad_token_id):\n",
    "    bsz, seq_len = len(tokens), max(len(t) for t in tokens)\n",
    "    input_ids = torch.full((bsz, seq_len), pad_token_id, dtype=torch.long)\n",
    "    for i, x in enumerate(tokens):\n",
    "        input_ids[i, :len(x)] = torch.tensor(x, dtype=torch.long)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "843681cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_model(model, input_ids):\n",
    "    batch_size, seq_len = input_ids.shape\n",
    "    outputs = model(input_ids)\n",
    "    target_ids = torch.roll(input_ids, shifts=-1, dims=1)\n",
    "    losses = torch.nn.functional.cross_entropy(\n",
    "        outputs.view(batch_size*seq_len, -1),\n",
    "        target_ids.view(batch_size*seq_len),\n",
    "        reduction='none'\n",
    "    ).view(batch_size, seq_len)\n",
    "    losses[:, -1] = float('nan')  # Ignore loss for the last token\n",
    "    predictions = torch.argmax(outputs, dim=-1)\n",
    "    return losses, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc21ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 9: Prediction index = 0, Gold index = 1, Correct = False\n"
     ]
    }
   ],
   "source": [
    "max_token_len = 1024\n",
    "new_tokens, new_start_ids, new_end_ids = [], [], []\n",
    "\n",
    "for t, s, e in zip(tokens, start_indices, end_indices):\n",
    "    if len(t) > max_token_len:\n",
    "        num_to_crop = len(t) - max_token_len\n",
    "        new_tokens.append(t[-max_token_len:])\n",
    "        new_start_ids.append(s-num_to_crop)\n",
    "        new_end_ids.append(e-num_to_crop)\n",
    "    else:\n",
    "        new_tokens.append(t)\n",
    "        new_start_ids.append(s)\n",
    "        new_end_ids.append(e)\n",
    "    \n",
    "tokens, start_ids, end_ids = new_tokens, new_start_ids, new_end_ids\n",
    "\n",
    "pad_token_id = tokenizer.get_bos_token_id()\n",
    "input_ids = stack_sequences(tokens, pad_token_id)\n",
    "\n",
    "from minichat.gpt import GPT, GPTConfig\n",
    "\n",
    "\n",
    "config = GPTConfig(\n",
    "    sequence_len = 512,\n",
    "    n_layers = 12,\n",
    "    vocab_size = 50257,\n",
    "    emb_dim = 128,\n",
    "    n_heads = 8\n",
    ")\n",
    "\n",
    "model = GPT(config)\n",
    "losses, predictions = forward_model(model, input_ids)\n",
    "\n",
    "mean_losses = [losses[i, start_ids[i]:end_ids[i]-1].mean().item() for i in range(len(tokens))]  # exclude last token\n",
    "pred_idx = mean_losses.index(min(mean_losses))\n",
    "\n",
    "is_correct = (pred_idx == example['gold'])\n",
    "\n",
    "print(f\"Example {i}: Prediction index = {pred_idx}, Gold index = {example['gold']}, Correct = {is_correct}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02295af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minichat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
