{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbaee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284bfd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config, layer_idx):\n",
    "        super().__init__()     \n",
    "        self.layer_idx = layer_idx\n",
    "        self.n_head = config.n_head\n",
    "        self.n_kv_head = config.n_kv_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.head_dim = self.n_embd // self.n_head\n",
    "        assert self.n_embd % self.n_head == 0\n",
    "        self.c_q = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_k = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_v = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C =  x.size()\n",
    "\n",
    "        q = self.c_q(x).view(B, T, self.n_head, self.head_dim) # B, T, H, D\n",
    "        k = self.c_k(x).view(B, T, self.n_head, self.head_dim) # B, T, H, D\n",
    "        v = self.c_v(x).view(B, T, self.n_head, self.head_dim) # B, T, H, D\n",
    "\n",
    "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)  # B, H, T, D\n",
    "\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # B, H, T, D\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, -1) # B, H, T, D -> B, T, H, D -> B, T, C\n",
    "\n",
    "        y = self.c_proj(y) # B, T, C\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64aab30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4* config.n_embd, bias=False)\n",
    "        self.c_proj = nn.Linear(4*config.n_embd, config.n_embd, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = F.relu(x).square()\n",
    "        x = self.c_proj(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab58269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return F.rms_norm(x, (x.size(-1),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b505759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config, layer_idx):\n",
    "        super().__init__()\n",
    "        self.attn = CausalSelfAttention(config, layer_idx)\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(norm(x))\n",
    "        x = x + self.mlp(norm(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa35d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict({\n",
    "            \"wte\": nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            \"pte\": nn.Embedding(config.sequence_len, config.n_embd),\n",
    "            \"h\": nn.ModuleList([Block(config, layer_idx) for layer_idx in range(config.n_layer)])\n",
    "        })\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        head_size = config.n_embd // config.n_head\n",
    "    \n",
    "    def forward(self, idx, targets=None, loss_reduction='mean'):\n",
    "        B,T = idx.size()\n",
    "        x = self.transformer.wte(idx) + self.transformer.pte(torch.arange(T, device=idx.device))\n",
    "        x = norm(x)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = norm(x)\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x)\n",
    "            logits = logits.float()\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1, reduction=loss_reduction)\n",
    "            return loss, logits\n",
    "\n",
    "        else:\n",
    "            logits = self.lm_head(x)\n",
    "            return logits\n",
    "    \n",
    "    def generate(self, idx, seq_len):\n",
    "        for _ in range(seq_len):\n",
    "            # Crop context if it exceeds sequence_len\n",
    "            idx_crop = idx if idx.size(1) <= self.config.sequence_len else idx[:, -self.config.sequence_len:]\n",
    "            logits = self(idx_crop)\n",
    "            last_idx = logits[:, -1, :]\n",
    "            last_token = F.softmax(last_idx, dim=-1)\n",
    "            idx_next = torch.multinomial(last_token, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d8edb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-31 01:51:24--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.1’\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-10-31 01:51:25 (29.7 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
      "\n",
      "200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.1’\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-10-31 01:51:25 (29.7 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data loading from shakespeare dataset\n",
    "\n",
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7833f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbc4b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character level coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a66a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(set(text))\n",
    "\n",
    "train_size = int(0.9 * len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36f9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = {}\n",
    "decode = {}\n",
    "for i, t in enumerate(set(text)):\n",
    "    encode[t] = i\n",
    "    decode[i] = t\n",
    "\n",
    "encoder = lambda text: [encode[x] for x in text]\n",
    "decoder = lambda ids: ''.join(decode[i] for i in ids)\n",
    "\n",
    "data = encoder(text)\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71310e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Byte Pair Encoding (BPE) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c02ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to bytes for BPE\n",
    "text_bytes = text.encode(\"utf-8\")\n",
    "ids = list(text_bytes)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for i, j in zip(ids, ids[1:]):\n",
    "        counts[(i, j)] = counts.get((i, j), 0) + 1\n",
    "    return counts\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if ids[i] == pair[0] and i < len(ids) - 1 and ids[i + 1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf4abbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (101, 32) into a new token 256\n",
      "merging (116, 104) into a new token 257\n",
      "merging (116, 104) into a new token 257\n",
      "merging (116, 32) into a new token 258\n",
      "merging (116, 32) into a new token 258\n",
      "merging (115, 32) into a new token 259\n",
      "merging (115, 32) into a new token 259\n",
      "merging (100, 32) into a new token 260\n",
      "merging (100, 32) into a new token 260\n",
      "merging (44, 32) into a new token 261\n",
      "merging (44, 32) into a new token 261\n",
      "merging (111, 117) into a new token 262\n",
      "merging (111, 117) into a new token 262\n",
      "merging (101, 114) into a new token 263\n",
      "merging (101, 114) into a new token 263\n",
      "merging (105, 110) into a new token 264\n",
      "merging (105, 110) into a new token 264\n",
      "merging (121, 32) into a new token 265\n",
      "merging (121, 32) into a new token 265\n",
      "merging (97, 110) into a new token 266\n",
      "merging (97, 110) into a new token 266\n",
      "merging (58, 10) into a new token 267\n",
      "merging (58, 10) into a new token 267\n",
      "merging (111, 114) into a new token 268\n",
      "merging (111, 114) into a new token 268\n",
      "merging (111, 32) into a new token 269\n",
      "merging (111, 32) into a new token 269\n",
      "merging (101, 110) into a new token 270\n",
      "merging (101, 110) into a new token 270\n",
      "merging (10, 10) into a new token 271\n",
      "merging (10, 10) into a new token 271\n",
      "merging (97, 114) into a new token 272\n",
      "merging (97, 114) into a new token 272\n",
      "merging (32, 257) into a new token 273\n",
      "merging (32, 257) into a new token 273\n",
      "merging (111, 110) into a new token 274\n",
      "merging (111, 110) into a new token 274\n",
      "merging (108, 108) into a new token 275\n",
      "Compression ratio: 1.26\n",
      "Final vocab size: 276\n",
      "Number of merges: 20\n",
      "merging (108, 108) into a new token 275\n",
      "Compression ratio: 1.26\n",
      "Final vocab size: 276\n",
      "Number of merges: 20\n"
     ]
    }
   ],
   "source": [
    "# Train BPE tokenizer\n",
    "vocab_size_bpe = 276  # 256 bytes + 20 merges\n",
    "num_merges = vocab_size_bpe - 256\n",
    "merges = {}\n",
    "\n",
    "for i in range(num_merges):\n",
    "    stats = get_stats(ids)\n",
    "    if not stats:\n",
    "        break\n",
    "    # Find the most frequent pair\n",
    "    pair = max(stats, key=stats.get)\n",
    "    idx = 256 + i  # new token index\n",
    "    print(f\"merging {pair} into a new token {idx}\")\n",
    "    ids = merge(ids, pair, idx)\n",
    "    merges[pair] = idx\n",
    "\n",
    "print(f\"Compression ratio: {len(text_bytes) / len(ids):.2f}\")\n",
    "print(f\"Final vocab size: {vocab_size_bpe}\")\n",
    "print(f\"Number of merges: {len(merges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c2b1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: hello world! this is a test.\n",
      "Encoded: [104, 101, 275, 269, 119, 268, 108, 100, 33, 273, 105, 259, 105, 259, 97, 32, 116, 101, 115, 116, 46]\n",
      "Decoded: hello world! this is a test.\n",
      "Round-trip successful: True\n",
      "Original text length: 1115394\n",
      "BPE encoded length: 882737\n",
      "Compression ratio: 1.26\n",
      "Original text length: 1115394\n",
      "BPE encoded length: 882737\n",
      "Compression ratio: 1.26\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary mapping for BPE\n",
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode_bpe(ids):\n",
    "    # Convert tokens back to bytes, then to string\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "def encode_bpe(text):\n",
    "    # Convert text to bytes, then apply merges\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    while len(tokens) >= 2:\n",
    "        stats = get_stats(tokens)\n",
    "        pair = min(stats, key=lambda pair: merges.get(pair, float(\"inf\")))\n",
    "        if pair not in merges:\n",
    "            break\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "    return tokens\n",
    "\n",
    "# Test the BPE tokenizer\n",
    "test_text = \"hello world! this is a test.\"\n",
    "encoded = encode_bpe(test_text)\n",
    "decoded = decode_bpe(encoded)\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Encoded: {encoded}\")\n",
    "print(f\"Decoded: {decoded}\")\n",
    "print(f\"Round-trip successful: {test_text == decoded}\")\n",
    "\n",
    "# Encode the full text with BPE\n",
    "bpe_data = encode_bpe(text)\n",
    "train_size_bpe = int(0.9 * len(bpe_data))\n",
    "train_data_bpe = bpe_data[:train_size_bpe]\n",
    "val_data_bpe = bpe_data[train_size_bpe:]\n",
    "\n",
    "print(f\"Original text length: {len(text)}\")\n",
    "print(f\"BPE encoded length: {len(bpe_data)}\")\n",
    "print(f\"Compression ratio: {len(text) / len(bpe_data):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eba0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 256\n",
    "batch_size = 64\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(1443)\n",
    "\n",
    "def get_data(split='train', device='cuda', use_bpe=True):\n",
    "    if use_bpe:\n",
    "        data = train_data_bpe if split == 'train' else val_data_bpe\n",
    "    else:\n",
    "        data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([torch.tensor(data[i:i+block_size]) for i in ix])\n",
    "    y = torch.stack([torch.tensor(data[i+1:i+block_size+1]) for i in ix])\n",
    "    if device == 'cuda':\n",
    "        return x.cuda(), y.cuda()\n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = get_data('train', use_bpe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b0cde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    sequence_len: int = block_size\n",
    "    vocab_size: int = vocab_size_bpe  # Use BPE vocab size\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 6\n",
    "    n_kv_head: int = 6\n",
    "    n_embd: int = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "524b7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GPT(GPTConfig)\n",
    "model = model.cuda()\n",
    "optim = torch.optim.AdamW(model.parameters(),lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, T_0=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "392ece9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 5.8414177894592285\n",
      "Epoch: 0, Batch: 1, Loss: 4.737900733947754\n",
      "Epoch: 0, Batch: 1, Loss: 4.737900733947754\n",
      "Epoch: 0, Batch: 2, Loss: 4.426560401916504\n",
      "Epoch: 0, Batch: 2, Loss: 4.426560401916504\n",
      "Epoch: 0, Batch: 3, Loss: 4.261688232421875\n",
      "Epoch: 0, Batch: 3, Loss: 4.261688232421875\n",
      "Epoch: 0, Batch: 4, Loss: 4.116363048553467\n",
      "Epoch: 0, Batch: 4, Loss: 4.116363048553467\n",
      "Epoch: 0, Batch: 5, Loss: 4.066916465759277\n",
      "Epoch: 0, Batch: 5, Loss: 4.066916465759277\n",
      "Epoch: 0, Batch: 6, Loss: 4.019004821777344\n",
      "Epoch: 0, Batch: 6, Loss: 4.019004821777344\n",
      "Epoch: 0, Batch: 7, Loss: 3.9871513843536377\n",
      "Epoch: 0, Batch: 7, Loss: 3.9871513843536377\n",
      "Epoch: 0, Batch: 8, Loss: 3.9429831504821777\n",
      "Epoch: 0, Batch: 8, Loss: 3.9429831504821777\n",
      "Epoch: 0, Batch: 9, Loss: 3.856572151184082\n",
      "Epoch: 0, Batch: 9, Loss: 3.856572151184082\n",
      "Epoch: 0, Batch: 10, Loss: 3.8263816833496094\n",
      "Epoch: 0, Batch: 10, Loss: 3.8263816833496094\n",
      "Epoch: 0, Batch: 11, Loss: 3.805037021636963\n",
      "Epoch: 0, Batch: 11, Loss: 3.805037021636963\n",
      "Epoch: 0, Batch: 12, Loss: 3.7241625785827637\n",
      "Epoch: 0, Batch: 12, Loss: 3.7241625785827637\n",
      "Epoch: 0, Batch: 13, Loss: 3.7423884868621826\n",
      "Epoch: 0, Batch: 13, Loss: 3.7423884868621826\n",
      "Epoch: 0, Batch: 14, Loss: 3.7031514644622803\n",
      "Epoch: 0, Batch: 14, Loss: 3.7031514644622803\n",
      "Epoch: 0, Batch: 15, Loss: 3.7019295692443848\n",
      "Epoch: 0, Batch: 15, Loss: 3.7019295692443848\n",
      "Epoch: 0, Batch: 16, Loss: 3.6875977516174316\n",
      "Epoch: 0, Batch: 16, Loss: 3.6875977516174316\n",
      "Epoch: 0, Batch: 17, Loss: 3.6717307567596436\n",
      "Epoch: 0, Batch: 17, Loss: 3.6717307567596436\n",
      "Epoch: 0, Batch: 18, Loss: 3.633988380432129\n",
      "Epoch: 0, Batch: 18, Loss: 3.633988380432129\n",
      "Epoch: 0, Batch: 19, Loss: 3.6330809593200684\n",
      "Epoch: 0, Batch: 19, Loss: 3.6330809593200684\n",
      "Epoch: 0, Batch: 20, Loss: 3.640331983566284\n",
      "Epoch: 0, Batch: 20, Loss: 3.640331983566284\n",
      "Epoch: 0, Batch: 21, Loss: 3.580601215362549\n",
      "Epoch: 0, Batch: 21, Loss: 3.580601215362549\n",
      "Epoch: 0, Batch: 22, Loss: 3.515328884124756\n",
      "Epoch: 0, Batch: 22, Loss: 3.515328884124756\n",
      "Epoch: 0, Batch: 23, Loss: 3.4721713066101074\n",
      "Epoch: 0, Batch: 23, Loss: 3.4721713066101074\n",
      "Epoch: 0, Batch: 24, Loss: 3.453228235244751\n",
      "Epoch: 0, Batch: 24, Loss: 3.453228235244751\n",
      "Epoch: 0, Batch: 25, Loss: 3.38277268409729\n",
      "Epoch: 0, Batch: 25, Loss: 3.38277268409729\n",
      "Epoch: 0, Batch: 26, Loss: 3.3316421508789062\n",
      "Epoch: 0, Batch: 26, Loss: 3.3316421508789062\n",
      "Epoch: 0, Batch: 27, Loss: 3.3050477504730225\n",
      "Epoch: 0, Batch: 27, Loss: 3.3050477504730225\n",
      "Epoch: 0, Batch: 28, Loss: 3.30081844329834\n",
      "Epoch: 0, Batch: 28, Loss: 3.30081844329834\n",
      "Epoch: 0, Batch: 29, Loss: 3.2676403522491455\n",
      "Epoch: 0, Batch: 29, Loss: 3.2676403522491455\n",
      "Epoch: 0, Batch: 30, Loss: 3.254833698272705\n",
      "Epoch: 0, Batch: 30, Loss: 3.254833698272705\n",
      "Epoch: 0, Batch: 31, Loss: 3.244596481323242\n",
      "Epoch: 0, Batch: 31, Loss: 3.244596481323242\n",
      "Epoch: 0, Batch: 32, Loss: 3.2003402709960938\n",
      "Epoch: 0, Batch: 32, Loss: 3.2003402709960938\n",
      "Epoch: 0, Batch: 33, Loss: 3.2201075553894043\n",
      "Epoch: 0, Batch: 33, Loss: 3.2201075553894043\n",
      "Epoch: 0, Batch: 34, Loss: 3.205310344696045\n",
      "Epoch: 0, Batch: 34, Loss: 3.205310344696045\n",
      "Epoch: 0, Batch: 35, Loss: 3.2041735649108887\n",
      "Epoch: 0, Batch: 35, Loss: 3.2041735649108887\n",
      "Epoch: 0, Batch: 36, Loss: 3.198580741882324\n",
      "Epoch: 0, Batch: 36, Loss: 3.198580741882324\n",
      "Epoch: 0, Batch: 37, Loss: 3.199596881866455\n",
      "Epoch: 0, Batch: 37, Loss: 3.199596881866455\n",
      "Epoch: 0, Batch: 38, Loss: 3.1754815578460693\n",
      "Epoch: 0, Batch: 38, Loss: 3.1754815578460693\n",
      "Epoch: 0, Batch: 39, Loss: 3.2027549743652344\n",
      "Epoch: 0, Batch: 39, Loss: 3.2027549743652344\n",
      "Epoch: 0, Batch: 40, Loss: 3.1864430904388428\n",
      "Epoch: 0, Batch: 40, Loss: 3.1864430904388428\n",
      "Epoch: 0, Batch: 41, Loss: 3.1562423706054688\n",
      "Epoch: 0, Batch: 41, Loss: 3.1562423706054688\n",
      "Epoch: 0, Batch: 42, Loss: 3.1421425342559814\n",
      "Epoch: 0, Batch: 42, Loss: 3.1421425342559814\n",
      "Epoch: 0, Batch: 43, Loss: 3.142759323120117\n",
      "Epoch: 0, Batch: 43, Loss: 3.142759323120117\n",
      "Epoch: 0, Batch: 44, Loss: 3.13474178314209\n",
      "Epoch: 0, Batch: 44, Loss: 3.13474178314209\n",
      "Epoch: 0, Batch: 45, Loss: 3.121058702468872\n",
      "Epoch: 0, Batch: 45, Loss: 3.121058702468872\n",
      "Epoch: 0, Batch: 46, Loss: 3.119145631790161\n",
      "Epoch: 0, Batch: 46, Loss: 3.119145631790161\n",
      "Epoch: 0, Batch: 47, Loss: 3.0828640460968018\n",
      "Epoch: 0, Batch: 47, Loss: 3.0828640460968018\n",
      "Epoch: 0, Batch: 48, Loss: 3.087571620941162\n",
      "Epoch: 0, Batch: 48, Loss: 3.087571620941162\n",
      "Epoch: 0, Batch: 49, Loss: 3.0520989894866943\n",
      "Epoch: 0, Batch: 49, Loss: 3.0520989894866943\n",
      "Epoch: 0, Batch: 50, Loss: 3.045389413833618\n",
      "Epoch: 0, Batch: 50, Loss: 3.045389413833618\n",
      "Epoch: 0, Batch: 51, Loss: 3.03962779045105\n",
      "Epoch: 0, Batch: 51, Loss: 3.03962779045105\n",
      "Epoch: 0, Batch: 52, Loss: 3.0502312183380127\n",
      "Epoch: 0, Batch: 52, Loss: 3.0502312183380127\n",
      "Epoch: 0, Batch: 53, Loss: 3.0473058223724365\n",
      "Epoch: 0, Batch: 53, Loss: 3.0473058223724365\n",
      "Epoch: 0, Batch: 54, Loss: 3.051213264465332\n",
      "Epoch: 0, Batch: 54, Loss: 3.051213264465332\n",
      "Epoch: 0, Batch: 55, Loss: 3.025808334350586\n",
      "Epoch: 0, Batch: 55, Loss: 3.025808334350586\n",
      "Epoch: 0, Batch: 56, Loss: 3.0532987117767334\n",
      "Epoch: 0, Batch: 56, Loss: 3.0532987117767334\n",
      "Epoch: 0, Batch: 57, Loss: 3.0379042625427246\n",
      "Epoch: 0, Batch: 57, Loss: 3.0379042625427246\n",
      "Epoch: 0, Batch: 58, Loss: 3.049945831298828\n",
      "Epoch: 0, Batch: 58, Loss: 3.049945831298828\n",
      "Epoch: 0, Batch: 59, Loss: 3.0456418991088867\n",
      "Epoch: 0, Batch: 59, Loss: 3.0456418991088867\n",
      "Epoch: 0, Batch: 60, Loss: 3.039778709411621\n",
      "Epoch: 0, Batch: 60, Loss: 3.039778709411621\n",
      "Epoch: 0, Batch: 61, Loss: 3.020962953567505\n",
      "Epoch: 0, Batch: 61, Loss: 3.020962953567505\n",
      "Epoch: 0, Batch: 62, Loss: 3.043226480484009\n",
      "Epoch: 0, Batch: 62, Loss: 3.043226480484009\n",
      "Epoch: 0, Batch: 63, Loss: 3.0322563648223877\n",
      "Epoch: 0, Batch: 63, Loss: 3.0322563648223877\n",
      "Epoch: 0, Batch: 64, Loss: 3.033320903778076\n",
      "Epoch: 0, Batch: 64, Loss: 3.033320903778076\n",
      "Epoch: 0, Batch: 65, Loss: 3.0108723640441895\n",
      "Epoch: 0, Batch: 65, Loss: 3.0108723640441895\n",
      "Epoch: 0, Batch: 66, Loss: 3.0257112979888916\n",
      "Epoch: 0, Batch: 66, Loss: 3.0257112979888916\n",
      "Epoch: 0, Batch: 67, Loss: 3.004718780517578\n",
      "Epoch: 0, Batch: 67, Loss: 3.004718780517578\n",
      "Epoch: 0, Batch: 68, Loss: 2.9982504844665527\n",
      "Epoch: 0, Batch: 68, Loss: 2.9982504844665527\n",
      "Epoch: 0, Batch: 69, Loss: 2.9982399940490723\n",
      "Epoch: 0, Batch: 69, Loss: 2.9982399940490723\n",
      "Epoch: 0, Batch: 70, Loss: 3.009711742401123\n",
      "Epoch: 0, Batch: 70, Loss: 3.009711742401123\n",
      "Epoch: 0, Batch: 71, Loss: 3.0322699546813965\n",
      "Epoch: 0, Batch: 71, Loss: 3.0322699546813965\n",
      "Epoch: 0, Batch: 72, Loss: 2.9793853759765625\n",
      "Epoch: 0, Batch: 72, Loss: 2.9793853759765625\n",
      "Epoch: 0, Batch: 73, Loss: 2.994460344314575\n",
      "Epoch: 0, Batch: 73, Loss: 2.994460344314575\n",
      "Epoch: 0, Batch: 74, Loss: 2.973156452178955\n",
      "Epoch: 0, Batch: 74, Loss: 2.973156452178955\n",
      "Epoch: 0, Batch: 75, Loss: 3.0087907314300537\n",
      "Epoch: 0, Batch: 75, Loss: 3.0087907314300537\n",
      "Epoch: 0, Batch: 76, Loss: 2.984011650085449\n",
      "Epoch: 0, Batch: 76, Loss: 2.984011650085449\n",
      "Epoch: 0, Batch: 77, Loss: 2.9896907806396484\n",
      "Epoch: 0, Batch: 77, Loss: 2.9896907806396484\n",
      "Epoch: 0, Batch: 78, Loss: 2.9820854663848877\n",
      "Epoch: 0, Batch: 78, Loss: 2.9820854663848877\n",
      "Epoch: 0, Batch: 79, Loss: 3.0000414848327637\n",
      "Epoch: 0, Batch: 79, Loss: 3.0000414848327637\n",
      "Epoch: 0, Batch: 80, Loss: 2.9756112098693848\n",
      "Epoch: 0, Batch: 80, Loss: 2.9756112098693848\n",
      "Epoch: 0, Batch: 81, Loss: 2.992264747619629\n",
      "Epoch: 0, Batch: 81, Loss: 2.992264747619629\n",
      "Epoch: 0, Batch: 82, Loss: 2.977529764175415\n",
      "Epoch: 0, Batch: 82, Loss: 2.977529764175415\n",
      "Epoch: 0, Batch: 83, Loss: 2.9882876873016357\n",
      "Epoch: 0, Batch: 83, Loss: 2.9882876873016357\n",
      "Epoch: 0, Batch: 84, Loss: 2.976646900177002\n",
      "Epoch: 0, Batch: 84, Loss: 2.976646900177002\n",
      "Epoch: 0, Batch: 85, Loss: 3.0038506984710693\n",
      "Epoch: 0, Batch: 85, Loss: 3.0038506984710693\n",
      "Epoch: 0, Batch: 86, Loss: 2.956570625305176\n",
      "Epoch: 0, Batch: 86, Loss: 2.956570625305176\n",
      "Epoch: 0, Batch: 87, Loss: 2.9845101833343506\n",
      "Epoch: 0, Batch: 87, Loss: 2.9845101833343506\n",
      "Epoch: 0, Batch: 88, Loss: 2.957066059112549\n",
      "Epoch: 0, Batch: 88, Loss: 2.957066059112549\n",
      "Epoch: 0, Batch: 89, Loss: 2.9534316062927246\n",
      "Epoch: 0, Batch: 89, Loss: 2.9534316062927246\n",
      "Epoch: 0, Batch: 90, Loss: 2.9622251987457275\n",
      "Epoch: 0, Batch: 90, Loss: 2.9622251987457275\n",
      "Epoch: 0, Batch: 91, Loss: 2.9648988246917725\n",
      "Epoch: 0, Batch: 91, Loss: 2.9648988246917725\n",
      "Epoch: 0, Batch: 92, Loss: 2.9662370681762695\n",
      "Epoch: 0, Batch: 92, Loss: 2.9662370681762695\n",
      "Epoch: 0, Batch: 93, Loss: 2.9670028686523438\n",
      "Epoch: 0, Batch: 93, Loss: 2.9670028686523438\n",
      "Epoch: 0, Batch: 94, Loss: 2.969900131225586\n",
      "Epoch: 0, Batch: 94, Loss: 2.969900131225586\n",
      "Epoch: 0, Batch: 95, Loss: 2.961998462677002\n",
      "Epoch: 0, Batch: 95, Loss: 2.961998462677002\n",
      "Epoch: 0, Batch: 96, Loss: 2.986018180847168\n",
      "Epoch: 0, Batch: 96, Loss: 2.986018180847168\n",
      "Epoch: 0, Batch: 97, Loss: 2.94766902923584\n",
      "Epoch: 0, Batch: 97, Loss: 2.94766902923584\n",
      "Epoch: 0, Batch: 98, Loss: 2.946012258529663\n",
      "Epoch: 0, Batch: 98, Loss: 2.946012258529663\n",
      "Epoch: 0, Batch: 99, Loss: 2.958582878112793\n",
      "Epoch: 0, Batch: 99, Loss: 2.958582878112793\n",
      "Generated text: \u0000destaSayout th he sheentent as buscke pom R:\n",
      "YCEf siyoug�er,\n",
      "ARorod ly os.\n",
      "Whofor w hason thento w, sderet d; lt ad w<we cuy gh...\n",
      "Generated text: \u0000destaSayout th he sheentent as buscke pom R:\n",
      "YCEf siyoug�er,\n",
      "ARorod ly os.\n",
      "Whofor w hason thento w, sderet d; lt ad w<we cuy gh...\n",
      "Epoch: 1, Batch: 0, Loss: 2.943732261657715\n",
      "Epoch: 1, Batch: 0, Loss: 2.943732261657715\n",
      "Epoch: 1, Batch: 1, Loss: 2.942161798477173\n",
      "Epoch: 1, Batch: 1, Loss: 2.942161798477173\n",
      "Epoch: 1, Batch: 2, Loss: 2.94354510307312\n",
      "Epoch: 1, Batch: 2, Loss: 2.94354510307312\n",
      "Epoch: 1, Batch: 3, Loss: 2.965562343597412\n",
      "Epoch: 1, Batch: 3, Loss: 2.965562343597412\n",
      "Epoch: 1, Batch: 4, Loss: 2.956488609313965\n",
      "Epoch: 1, Batch: 4, Loss: 2.956488609313965\n",
      "Epoch: 1, Batch: 5, Loss: 2.94551682472229\n",
      "Epoch: 1, Batch: 5, Loss: 2.94551682472229\n",
      "Epoch: 1, Batch: 6, Loss: 2.948216676712036\n",
      "Epoch: 1, Batch: 6, Loss: 2.948216676712036\n",
      "Epoch: 1, Batch: 7, Loss: 2.9301061630249023\n",
      "Epoch: 1, Batch: 7, Loss: 2.9301061630249023\n",
      "Epoch: 1, Batch: 8, Loss: 2.9361135959625244\n",
      "Epoch: 1, Batch: 8, Loss: 2.9361135959625244\n",
      "Epoch: 1, Batch: 9, Loss: 2.943711042404175\n",
      "Epoch: 1, Batch: 9, Loss: 2.943711042404175\n",
      "Epoch: 1, Batch: 10, Loss: 2.9229509830474854\n",
      "Epoch: 1, Batch: 10, Loss: 2.9229509830474854\n",
      "Epoch: 1, Batch: 11, Loss: 2.933415412902832\n",
      "Epoch: 1, Batch: 11, Loss: 2.933415412902832\n",
      "Epoch: 1, Batch: 12, Loss: 2.9275686740875244\n",
      "Epoch: 1, Batch: 12, Loss: 2.9275686740875244\n",
      "Epoch: 1, Batch: 13, Loss: 2.9273600578308105\n",
      "Epoch: 1, Batch: 13, Loss: 2.9273600578308105\n",
      "Epoch: 1, Batch: 14, Loss: 2.9326021671295166\n",
      "Epoch: 1, Batch: 14, Loss: 2.9326021671295166\n",
      "Epoch: 1, Batch: 15, Loss: 2.9177403450012207\n",
      "Epoch: 1, Batch: 15, Loss: 2.9177403450012207\n",
      "Epoch: 1, Batch: 16, Loss: 2.95963191986084\n",
      "Epoch: 1, Batch: 16, Loss: 2.95963191986084\n",
      "Epoch: 1, Batch: 17, Loss: 2.9063096046447754\n",
      "Epoch: 1, Batch: 17, Loss: 2.9063096046447754\n",
      "Epoch: 1, Batch: 18, Loss: 2.953339099884033\n",
      "Epoch: 1, Batch: 18, Loss: 2.953339099884033\n",
      "Epoch: 1, Batch: 19, Loss: 2.92022705078125\n",
      "Epoch: 1, Batch: 19, Loss: 2.92022705078125\n",
      "Epoch: 1, Batch: 20, Loss: 2.926211357116699\n",
      "Epoch: 1, Batch: 20, Loss: 2.926211357116699\n",
      "Epoch: 1, Batch: 21, Loss: 2.938861131668091\n",
      "Epoch: 1, Batch: 21, Loss: 2.938861131668091\n",
      "Epoch: 1, Batch: 22, Loss: 2.927295207977295\n",
      "Epoch: 1, Batch: 22, Loss: 2.927295207977295\n",
      "Epoch: 1, Batch: 23, Loss: 2.9219775199890137\n",
      "Epoch: 1, Batch: 23, Loss: 2.9219775199890137\n",
      "Epoch: 1, Batch: 24, Loss: 2.947265863418579\n",
      "Epoch: 1, Batch: 24, Loss: 2.947265863418579\n",
      "Epoch: 1, Batch: 25, Loss: 2.929455041885376\n",
      "Epoch: 1, Batch: 25, Loss: 2.929455041885376\n",
      "Epoch: 1, Batch: 26, Loss: 2.9361486434936523\n",
      "Epoch: 1, Batch: 26, Loss: 2.9361486434936523\n",
      "Epoch: 1, Batch: 27, Loss: 2.931361198425293\n",
      "Epoch: 1, Batch: 27, Loss: 2.931361198425293\n",
      "Epoch: 1, Batch: 28, Loss: 2.915158271789551\n",
      "Epoch: 1, Batch: 28, Loss: 2.915158271789551\n",
      "Epoch: 1, Batch: 29, Loss: 2.922306776046753\n",
      "Epoch: 1, Batch: 29, Loss: 2.922306776046753\n",
      "Epoch: 1, Batch: 30, Loss: 2.904566526412964\n",
      "Epoch: 1, Batch: 30, Loss: 2.904566526412964\n",
      "Epoch: 1, Batch: 31, Loss: 2.919490337371826\n",
      "Epoch: 1, Batch: 31, Loss: 2.919490337371826\n",
      "Epoch: 1, Batch: 32, Loss: 2.911550998687744\n",
      "Epoch: 1, Batch: 32, Loss: 2.911550998687744\n",
      "Epoch: 1, Batch: 33, Loss: 2.920269012451172\n",
      "Epoch: 1, Batch: 33, Loss: 2.920269012451172\n",
      "Epoch: 1, Batch: 34, Loss: 2.9322972297668457\n",
      "Epoch: 1, Batch: 34, Loss: 2.9322972297668457\n",
      "Epoch: 1, Batch: 35, Loss: 2.9118638038635254\n",
      "Epoch: 1, Batch: 35, Loss: 2.9118638038635254\n",
      "Epoch: 1, Batch: 36, Loss: 2.920949935913086\n",
      "Epoch: 1, Batch: 36, Loss: 2.920949935913086\n",
      "Epoch: 1, Batch: 37, Loss: 2.9295246601104736\n",
      "Epoch: 1, Batch: 37, Loss: 2.9295246601104736\n",
      "Epoch: 1, Batch: 38, Loss: 2.9027559757232666\n",
      "Epoch: 1, Batch: 38, Loss: 2.9027559757232666\n",
      "Epoch: 1, Batch: 39, Loss: 2.9041450023651123\n",
      "Epoch: 1, Batch: 39, Loss: 2.9041450023651123\n",
      "Epoch: 1, Batch: 40, Loss: 2.902468681335449\n",
      "Epoch: 1, Batch: 40, Loss: 2.902468681335449\n",
      "Epoch: 1, Batch: 41, Loss: 2.9213595390319824\n",
      "Epoch: 1, Batch: 41, Loss: 2.9213595390319824\n",
      "Epoch: 1, Batch: 42, Loss: 2.953948974609375\n",
      "Epoch: 1, Batch: 42, Loss: 2.953948974609375\n",
      "Epoch: 1, Batch: 43, Loss: 2.940092086791992\n",
      "Epoch: 1, Batch: 43, Loss: 2.940092086791992\n",
      "Epoch: 1, Batch: 44, Loss: 2.9189250469207764\n",
      "Epoch: 1, Batch: 44, Loss: 2.9189250469207764\n",
      "Epoch: 1, Batch: 45, Loss: 2.921602249145508\n",
      "Epoch: 1, Batch: 45, Loss: 2.921602249145508\n",
      "Epoch: 1, Batch: 46, Loss: 2.897129774093628\n",
      "Epoch: 1, Batch: 46, Loss: 2.897129774093628\n",
      "Epoch: 1, Batch: 47, Loss: 2.898466110229492\n",
      "Epoch: 1, Batch: 47, Loss: 2.898466110229492\n",
      "Epoch: 1, Batch: 48, Loss: 2.9245927333831787\n",
      "Epoch: 1, Batch: 48, Loss: 2.9245927333831787\n",
      "Epoch: 1, Batch: 49, Loss: 2.923065423965454\n",
      "Epoch: 1, Batch: 49, Loss: 2.923065423965454\n",
      "Epoch: 1, Batch: 50, Loss: 2.899322271347046\n",
      "Epoch: 1, Batch: 50, Loss: 2.899322271347046\n",
      "Epoch: 1, Batch: 51, Loss: 2.914318084716797\n",
      "Epoch: 1, Batch: 51, Loss: 2.914318084716797\n",
      "Epoch: 1, Batch: 52, Loss: 2.8912177085876465\n",
      "Epoch: 1, Batch: 52, Loss: 2.8912177085876465\n",
      "Epoch: 1, Batch: 53, Loss: 2.88918399810791\n",
      "Epoch: 1, Batch: 53, Loss: 2.88918399810791\n",
      "Epoch: 1, Batch: 54, Loss: 2.895717144012451\n",
      "Epoch: 1, Batch: 54, Loss: 2.895717144012451\n",
      "Epoch: 1, Batch: 55, Loss: 2.8937034606933594\n",
      "Epoch: 1, Batch: 55, Loss: 2.8937034606933594\n",
      "Epoch: 1, Batch: 56, Loss: 2.8981213569641113\n",
      "Epoch: 1, Batch: 56, Loss: 2.8981213569641113\n",
      "Epoch: 1, Batch: 57, Loss: 2.9146714210510254\n",
      "Epoch: 1, Batch: 57, Loss: 2.9146714210510254\n",
      "Epoch: 1, Batch: 58, Loss: 2.905522346496582\n",
      "Epoch: 1, Batch: 58, Loss: 2.905522346496582\n",
      "Epoch: 1, Batch: 59, Loss: 2.886741876602173\n",
      "Epoch: 1, Batch: 59, Loss: 2.886741876602173\n",
      "Epoch: 1, Batch: 60, Loss: 2.8992068767547607\n",
      "Epoch: 1, Batch: 60, Loss: 2.8992068767547607\n",
      "Epoch: 1, Batch: 61, Loss: 2.9141619205474854\n",
      "Epoch: 1, Batch: 61, Loss: 2.9141619205474854\n",
      "Epoch: 1, Batch: 62, Loss: 2.911182403564453\n",
      "Epoch: 1, Batch: 62, Loss: 2.911182403564453\n",
      "Epoch: 1, Batch: 63, Loss: 2.903918504714966\n",
      "Epoch: 1, Batch: 63, Loss: 2.903918504714966\n",
      "Epoch: 1, Batch: 64, Loss: 2.913944959640503\n",
      "Epoch: 1, Batch: 64, Loss: 2.913944959640503\n",
      "Epoch: 1, Batch: 65, Loss: 2.8974051475524902\n",
      "Epoch: 1, Batch: 65, Loss: 2.8974051475524902\n",
      "Epoch: 1, Batch: 66, Loss: 2.8926684856414795\n",
      "Epoch: 1, Batch: 66, Loss: 2.8926684856414795\n",
      "Epoch: 1, Batch: 67, Loss: 2.9088518619537354\n",
      "Epoch: 1, Batch: 67, Loss: 2.9088518619537354\n",
      "Epoch: 1, Batch: 68, Loss: 2.8912415504455566\n",
      "Epoch: 1, Batch: 68, Loss: 2.8912415504455566\n",
      "Epoch: 1, Batch: 69, Loss: 2.8935940265655518\n",
      "Epoch: 1, Batch: 69, Loss: 2.8935940265655518\n",
      "Epoch: 1, Batch: 70, Loss: 2.8986611366271973\n",
      "Epoch: 1, Batch: 70, Loss: 2.8986611366271973\n",
      "Epoch: 1, Batch: 71, Loss: 2.867438316345215\n",
      "Epoch: 1, Batch: 71, Loss: 2.867438316345215\n",
      "Epoch: 1, Batch: 72, Loss: 2.8929617404937744\n",
      "Epoch: 1, Batch: 72, Loss: 2.8929617404937744\n",
      "Epoch: 1, Batch: 73, Loss: 2.8997349739074707\n",
      "Epoch: 1, Batch: 73, Loss: 2.8997349739074707\n",
      "Epoch: 1, Batch: 74, Loss: 2.894761085510254\n",
      "Epoch: 1, Batch: 74, Loss: 2.894761085510254\n",
      "Epoch: 1, Batch: 75, Loss: 2.855104923248291\n",
      "Epoch: 1, Batch: 75, Loss: 2.855104923248291\n",
      "Epoch: 1, Batch: 76, Loss: 2.8625519275665283\n",
      "Epoch: 1, Batch: 76, Loss: 2.8625519275665283\n",
      "Epoch: 1, Batch: 77, Loss: 2.8784971237182617\n",
      "Epoch: 1, Batch: 77, Loss: 2.8784971237182617\n",
      "Epoch: 1, Batch: 78, Loss: 2.874056339263916\n",
      "Epoch: 1, Batch: 78, Loss: 2.874056339263916\n",
      "Epoch: 1, Batch: 79, Loss: 2.8813223838806152\n",
      "Epoch: 1, Batch: 79, Loss: 2.8813223838806152\n",
      "Epoch: 1, Batch: 80, Loss: 2.8719098567962646\n",
      "Epoch: 1, Batch: 80, Loss: 2.8719098567962646\n",
      "Epoch: 1, Batch: 81, Loss: 2.868435859680176\n",
      "Epoch: 1, Batch: 81, Loss: 2.868435859680176\n",
      "Epoch: 1, Batch: 82, Loss: 2.8876519203186035\n",
      "Epoch: 1, Batch: 82, Loss: 2.8876519203186035\n",
      "Epoch: 1, Batch: 83, Loss: 2.880467414855957\n",
      "Epoch: 1, Batch: 83, Loss: 2.880467414855957\n",
      "Epoch: 1, Batch: 84, Loss: 2.8622283935546875\n",
      "Epoch: 1, Batch: 84, Loss: 2.8622283935546875\n",
      "Epoch: 1, Batch: 85, Loss: 2.864710807800293\n",
      "Epoch: 1, Batch: 85, Loss: 2.864710807800293\n",
      "Epoch: 1, Batch: 86, Loss: 2.8560030460357666\n",
      "Epoch: 1, Batch: 86, Loss: 2.8560030460357666\n",
      "Epoch: 1, Batch: 87, Loss: 2.8770456314086914\n",
      "Epoch: 1, Batch: 87, Loss: 2.8770456314086914\n",
      "Epoch: 1, Batch: 88, Loss: 2.859788417816162\n",
      "Epoch: 1, Batch: 88, Loss: 2.859788417816162\n",
      "Epoch: 1, Batch: 89, Loss: 2.8728957176208496\n",
      "Epoch: 1, Batch: 89, Loss: 2.8728957176208496\n",
      "Epoch: 1, Batch: 90, Loss: 2.8805601596832275\n",
      "Epoch: 1, Batch: 90, Loss: 2.8805601596832275\n",
      "Epoch: 1, Batch: 91, Loss: 2.848186492919922\n",
      "Epoch: 1, Batch: 91, Loss: 2.848186492919922\n",
      "Epoch: 1, Batch: 92, Loss: 2.857001781463623\n",
      "Epoch: 1, Batch: 92, Loss: 2.857001781463623\n",
      "Epoch: 1, Batch: 93, Loss: 2.8762104511260986\n",
      "Epoch: 1, Batch: 93, Loss: 2.8762104511260986\n",
      "Epoch: 1, Batch: 94, Loss: 2.8755440711975098\n",
      "Epoch: 1, Batch: 94, Loss: 2.8755440711975098\n",
      "Epoch: 1, Batch: 95, Loss: 2.8482043743133545\n",
      "Epoch: 1, Batch: 95, Loss: 2.8482043743133545\n",
      "Epoch: 1, Batch: 96, Loss: 2.8715322017669678\n",
      "Epoch: 1, Batch: 96, Loss: 2.8715322017669678\n",
      "Epoch: 1, Batch: 97, Loss: 2.844339370727539\n",
      "Epoch: 1, Batch: 97, Loss: 2.844339370727539\n",
      "Epoch: 1, Batch: 98, Loss: 2.884253978729248\n",
      "Epoch: 1, Batch: 98, Loss: 2.884253978729248\n",
      "Epoch: 1, Batch: 99, Loss: 2.8716907501220703\n",
      "Epoch: 1, Batch: 99, Loss: 2.8716907501220703\n",
      "Generated text: \u0000en\u000f Ybove rame to me:\n",
      "Tdese a mave w, anke'll the weringelove had ingyst me hidelik\n",
      "Direat bre, we ng hasing mman;\n",
      "Besalithoure...\n",
      "Generated text: \u0000en\u000f Ybove rame to me:\n",
      "Tdese a mave w, anke'll the weringelove had ingyst me hidelik\n",
      "Direat bre, we ng hasing mman;\n",
      "Besalithoure...\n",
      "Epoch: 2, Batch: 0, Loss: 2.8588476181030273\n",
      "Epoch: 2, Batch: 0, Loss: 2.8588476181030273\n",
      "Epoch: 2, Batch: 1, Loss: 2.8763599395751953\n",
      "Epoch: 2, Batch: 1, Loss: 2.8763599395751953\n",
      "Epoch: 2, Batch: 2, Loss: 2.8774325847625732\n",
      "Epoch: 2, Batch: 2, Loss: 2.8774325847625732\n",
      "Epoch: 2, Batch: 3, Loss: 2.8897910118103027\n",
      "Epoch: 2, Batch: 3, Loss: 2.8897910118103027\n",
      "Epoch: 2, Batch: 4, Loss: 2.8650269508361816\n",
      "Epoch: 2, Batch: 4, Loss: 2.8650269508361816\n",
      "Epoch: 2, Batch: 5, Loss: 2.839535713195801\n",
      "Epoch: 2, Batch: 5, Loss: 2.839535713195801\n",
      "Epoch: 2, Batch: 6, Loss: 2.8731589317321777\n",
      "Epoch: 2, Batch: 6, Loss: 2.8731589317321777\n",
      "Epoch: 2, Batch: 7, Loss: 2.8858754634857178\n",
      "Epoch: 2, Batch: 7, Loss: 2.8858754634857178\n",
      "Epoch: 2, Batch: 8, Loss: 2.880922794342041\n",
      "Epoch: 2, Batch: 8, Loss: 2.880922794342041\n",
      "Epoch: 2, Batch: 9, Loss: 2.8533577919006348\n",
      "Epoch: 2, Batch: 9, Loss: 2.8533577919006348\n",
      "Epoch: 2, Batch: 10, Loss: 2.8498735427856445\n",
      "Epoch: 2, Batch: 10, Loss: 2.8498735427856445\n",
      "Epoch: 2, Batch: 11, Loss: 2.835540771484375\n",
      "Epoch: 2, Batch: 11, Loss: 2.835540771484375\n",
      "Epoch: 2, Batch: 12, Loss: 2.845489501953125\n",
      "Epoch: 2, Batch: 12, Loss: 2.845489501953125\n",
      "Epoch: 2, Batch: 13, Loss: 2.8689322471618652\n",
      "Epoch: 2, Batch: 13, Loss: 2.8689322471618652\n",
      "Epoch: 2, Batch: 14, Loss: 2.8668222427368164\n",
      "Epoch: 2, Batch: 14, Loss: 2.8668222427368164\n",
      "Epoch: 2, Batch: 15, Loss: 2.8414642810821533\n",
      "Epoch: 2, Batch: 15, Loss: 2.8414642810821533\n",
      "Epoch: 2, Batch: 16, Loss: 2.8117423057556152\n",
      "Epoch: 2, Batch: 16, Loss: 2.8117423057556152\n",
      "Epoch: 2, Batch: 17, Loss: 2.8566391468048096\n",
      "Epoch: 2, Batch: 17, Loss: 2.8566391468048096\n",
      "Epoch: 2, Batch: 18, Loss: 2.8270788192749023\n",
      "Epoch: 2, Batch: 18, Loss: 2.8270788192749023\n",
      "Epoch: 2, Batch: 19, Loss: 2.8654253482818604\n",
      "Epoch: 2, Batch: 19, Loss: 2.8654253482818604\n",
      "Epoch: 2, Batch: 20, Loss: 2.8587493896484375\n",
      "Epoch: 2, Batch: 20, Loss: 2.8587493896484375\n",
      "Epoch: 2, Batch: 21, Loss: 2.87727952003479\n",
      "Epoch: 2, Batch: 21, Loss: 2.87727952003479\n",
      "Epoch: 2, Batch: 22, Loss: 2.8558804988861084\n",
      "Epoch: 2, Batch: 22, Loss: 2.8558804988861084\n",
      "Epoch: 2, Batch: 23, Loss: 2.862865924835205\n",
      "Epoch: 2, Batch: 23, Loss: 2.862865924835205\n",
      "Epoch: 2, Batch: 24, Loss: 2.8400392532348633\n",
      "Epoch: 2, Batch: 24, Loss: 2.8400392532348633\n",
      "Epoch: 2, Batch: 25, Loss: 2.8485255241394043\n",
      "Epoch: 2, Batch: 25, Loss: 2.8485255241394043\n",
      "Epoch: 2, Batch: 26, Loss: 2.8441338539123535\n",
      "Epoch: 2, Batch: 26, Loss: 2.8441338539123535\n",
      "Epoch: 2, Batch: 27, Loss: 2.8414411544799805\n",
      "Epoch: 2, Batch: 27, Loss: 2.8414411544799805\n",
      "Epoch: 2, Batch: 28, Loss: 2.8445796966552734\n",
      "Epoch: 2, Batch: 28, Loss: 2.8445796966552734\n",
      "Epoch: 2, Batch: 29, Loss: 2.8580079078674316\n",
      "Epoch: 2, Batch: 29, Loss: 2.8580079078674316\n",
      "Epoch: 2, Batch: 30, Loss: 2.863529682159424\n",
      "Epoch: 2, Batch: 30, Loss: 2.863529682159424\n",
      "Epoch: 2, Batch: 31, Loss: 2.831606388092041\n",
      "Epoch: 2, Batch: 31, Loss: 2.831606388092041\n",
      "Epoch: 2, Batch: 32, Loss: 2.8279378414154053\n",
      "Epoch: 2, Batch: 32, Loss: 2.8279378414154053\n",
      "Epoch: 2, Batch: 33, Loss: 2.859815835952759\n",
      "Epoch: 2, Batch: 33, Loss: 2.859815835952759\n",
      "Epoch: 2, Batch: 34, Loss: 2.8242006301879883\n",
      "Epoch: 2, Batch: 34, Loss: 2.8242006301879883\n",
      "Epoch: 2, Batch: 35, Loss: 2.8314547538757324\n",
      "Epoch: 2, Batch: 35, Loss: 2.8314547538757324\n",
      "Epoch: 2, Batch: 36, Loss: 2.8445606231689453\n",
      "Epoch: 2, Batch: 36, Loss: 2.8445606231689453\n",
      "Epoch: 2, Batch: 37, Loss: 2.836124897003174\n",
      "Epoch: 2, Batch: 37, Loss: 2.836124897003174\n",
      "Epoch: 2, Batch: 38, Loss: 2.8377792835235596\n",
      "Epoch: 2, Batch: 38, Loss: 2.8377792835235596\n",
      "Epoch: 2, Batch: 39, Loss: 2.830226421356201\n",
      "Epoch: 2, Batch: 39, Loss: 2.830226421356201\n",
      "Epoch: 2, Batch: 40, Loss: 2.827082395553589\n",
      "Epoch: 2, Batch: 40, Loss: 2.827082395553589\n",
      "Epoch: 2, Batch: 41, Loss: 2.841130256652832\n",
      "Epoch: 2, Batch: 41, Loss: 2.841130256652832\n",
      "Epoch: 2, Batch: 42, Loss: 2.8360893726348877\n",
      "Epoch: 2, Batch: 42, Loss: 2.8360893726348877\n",
      "Epoch: 2, Batch: 43, Loss: 2.8374547958374023\n",
      "Epoch: 2, Batch: 43, Loss: 2.8374547958374023\n",
      "Epoch: 2, Batch: 44, Loss: 2.858341693878174\n",
      "Epoch: 2, Batch: 44, Loss: 2.858341693878174\n",
      "Epoch: 2, Batch: 45, Loss: 2.832808494567871\n",
      "Epoch: 2, Batch: 45, Loss: 2.832808494567871\n",
      "Epoch: 2, Batch: 46, Loss: 2.832989454269409\n",
      "Epoch: 2, Batch: 46, Loss: 2.832989454269409\n",
      "Epoch: 2, Batch: 47, Loss: 2.8218674659729004\n",
      "Epoch: 2, Batch: 47, Loss: 2.8218674659729004\n",
      "Epoch: 2, Batch: 48, Loss: 2.8017239570617676\n",
      "Epoch: 2, Batch: 48, Loss: 2.8017239570617676\n",
      "Epoch: 2, Batch: 49, Loss: 2.822660446166992\n",
      "Epoch: 2, Batch: 49, Loss: 2.822660446166992\n",
      "Epoch: 2, Batch: 50, Loss: 2.8289237022399902\n",
      "Epoch: 2, Batch: 50, Loss: 2.8289237022399902\n",
      "Epoch: 2, Batch: 51, Loss: 2.804969310760498\n",
      "Epoch: 2, Batch: 51, Loss: 2.804969310760498\n",
      "Epoch: 2, Batch: 52, Loss: 2.8200957775115967\n",
      "Epoch: 2, Batch: 52, Loss: 2.8200957775115967\n",
      "Epoch: 2, Batch: 53, Loss: 2.8315696716308594\n",
      "Epoch: 2, Batch: 53, Loss: 2.8315696716308594\n",
      "Epoch: 2, Batch: 54, Loss: 2.865054130554199\n",
      "Epoch: 2, Batch: 54, Loss: 2.865054130554199\n",
      "Epoch: 2, Batch: 55, Loss: 2.8097705841064453\n",
      "Epoch: 2, Batch: 55, Loss: 2.8097705841064453\n",
      "Epoch: 2, Batch: 56, Loss: 2.8258249759674072\n",
      "Epoch: 2, Batch: 56, Loss: 2.8258249759674072\n",
      "Epoch: 2, Batch: 57, Loss: 2.829787015914917\n",
      "Epoch: 2, Batch: 57, Loss: 2.829787015914917\n",
      "Epoch: 2, Batch: 58, Loss: 2.8105931282043457\n",
      "Epoch: 2, Batch: 58, Loss: 2.8105931282043457\n",
      "Epoch: 2, Batch: 59, Loss: 2.820974826812744\n",
      "Epoch: 2, Batch: 59, Loss: 2.820974826812744\n",
      "Epoch: 2, Batch: 60, Loss: 2.7973902225494385\n",
      "Epoch: 2, Batch: 60, Loss: 2.7973902225494385\n",
      "Epoch: 2, Batch: 61, Loss: 2.8393921852111816\n",
      "Epoch: 2, Batch: 61, Loss: 2.8393921852111816\n",
      "Epoch: 2, Batch: 62, Loss: 2.8507416248321533\n",
      "Epoch: 2, Batch: 62, Loss: 2.8507416248321533\n",
      "Epoch: 2, Batch: 63, Loss: 2.84011173248291\n",
      "Epoch: 2, Batch: 63, Loss: 2.84011173248291\n",
      "Epoch: 2, Batch: 64, Loss: 2.8508059978485107\n",
      "Epoch: 2, Batch: 64, Loss: 2.8508059978485107\n",
      "Epoch: 2, Batch: 65, Loss: 2.845829963684082\n",
      "Epoch: 2, Batch: 65, Loss: 2.845829963684082\n",
      "Epoch: 2, Batch: 66, Loss: 2.8321034908294678\n",
      "Epoch: 2, Batch: 66, Loss: 2.8321034908294678\n",
      "Epoch: 2, Batch: 67, Loss: 2.8314146995544434\n",
      "Epoch: 2, Batch: 67, Loss: 2.8314146995544434\n",
      "Epoch: 2, Batch: 68, Loss: 2.8238894939422607\n",
      "Epoch: 2, Batch: 68, Loss: 2.8238894939422607\n",
      "Epoch: 2, Batch: 69, Loss: 2.802173137664795\n",
      "Epoch: 2, Batch: 69, Loss: 2.802173137664795\n",
      "Epoch: 2, Batch: 70, Loss: 2.7916040420532227\n",
      "Epoch: 2, Batch: 70, Loss: 2.7916040420532227\n",
      "Epoch: 2, Batch: 71, Loss: 2.7958507537841797\n",
      "Epoch: 2, Batch: 71, Loss: 2.7958507537841797\n",
      "Epoch: 2, Batch: 72, Loss: 2.8153672218322754\n",
      "Epoch: 2, Batch: 72, Loss: 2.8153672218322754\n",
      "Epoch: 2, Batch: 73, Loss: 2.832150459289551\n",
      "Epoch: 2, Batch: 73, Loss: 2.832150459289551\n",
      "Epoch: 2, Batch: 74, Loss: 2.7942445278167725\n",
      "Epoch: 2, Batch: 74, Loss: 2.7942445278167725\n",
      "Epoch: 2, Batch: 75, Loss: 2.812565565109253\n",
      "Epoch: 2, Batch: 75, Loss: 2.812565565109253\n",
      "Epoch: 2, Batch: 76, Loss: 2.810145378112793\n",
      "Epoch: 2, Batch: 76, Loss: 2.810145378112793\n",
      "Epoch: 2, Batch: 77, Loss: 2.791417121887207\n",
      "Epoch: 2, Batch: 77, Loss: 2.791417121887207\n",
      "Epoch: 2, Batch: 78, Loss: 2.792839527130127\n",
      "Epoch: 2, Batch: 78, Loss: 2.792839527130127\n",
      "Epoch: 2, Batch: 79, Loss: 2.7856557369232178\n",
      "Epoch: 2, Batch: 79, Loss: 2.7856557369232178\n",
      "Epoch: 2, Batch: 80, Loss: 2.8351151943206787\n",
      "Epoch: 2, Batch: 80, Loss: 2.8351151943206787\n",
      "Epoch: 2, Batch: 81, Loss: 2.8190572261810303\n",
      "Epoch: 2, Batch: 81, Loss: 2.8190572261810303\n",
      "Epoch: 2, Batch: 82, Loss: 2.8278465270996094\n",
      "Epoch: 2, Batch: 82, Loss: 2.8278465270996094\n",
      "Epoch: 2, Batch: 83, Loss: 2.8103251457214355\n",
      "Epoch: 2, Batch: 83, Loss: 2.8103251457214355\n",
      "Epoch: 2, Batch: 84, Loss: 2.808497428894043\n",
      "Epoch: 2, Batch: 84, Loss: 2.808497428894043\n",
      "Epoch: 2, Batch: 85, Loss: 2.818434238433838\n",
      "Epoch: 2, Batch: 85, Loss: 2.818434238433838\n",
      "Epoch: 2, Batch: 86, Loss: 2.7930307388305664\n",
      "Epoch: 2, Batch: 86, Loss: 2.7930307388305664\n",
      "Epoch: 2, Batch: 87, Loss: 2.8185653686523438\n",
      "Epoch: 2, Batch: 87, Loss: 2.8185653686523438\n",
      "Epoch: 2, Batch: 88, Loss: 2.8078174591064453\n",
      "Epoch: 2, Batch: 88, Loss: 2.8078174591064453\n",
      "Epoch: 2, Batch: 89, Loss: 2.789628028869629\n",
      "Epoch: 2, Batch: 89, Loss: 2.789628028869629\n",
      "Epoch: 2, Batch: 90, Loss: 2.7885708808898926\n",
      "Epoch: 2, Batch: 90, Loss: 2.7885708808898926\n",
      "Epoch: 2, Batch: 91, Loss: 2.7978806495666504\n",
      "Epoch: 2, Batch: 91, Loss: 2.7978806495666504\n",
      "Epoch: 2, Batch: 92, Loss: 2.8043830394744873\n",
      "Epoch: 2, Batch: 92, Loss: 2.8043830394744873\n",
      "Epoch: 2, Batch: 93, Loss: 2.787703514099121\n",
      "Epoch: 2, Batch: 93, Loss: 2.787703514099121\n",
      "Epoch: 2, Batch: 94, Loss: 2.7662405967712402\n",
      "Epoch: 2, Batch: 94, Loss: 2.7662405967712402\n",
      "Epoch: 2, Batch: 95, Loss: 2.779275894165039\n",
      "Epoch: 2, Batch: 95, Loss: 2.779275894165039\n",
      "Epoch: 2, Batch: 96, Loss: 2.7722630500793457\n",
      "Epoch: 2, Batch: 96, Loss: 2.7722630500793457\n",
      "Epoch: 2, Batch: 97, Loss: 2.800117015838623\n",
      "Epoch: 2, Batch: 97, Loss: 2.800117015838623\n",
      "Epoch: 2, Batch: 98, Loss: 2.782599925994873\n",
      "Epoch: 2, Batch: 98, Loss: 2.782599925994873\n",
      "Epoch: 2, Batch: 99, Loss: 2.7777137756347656\n",
      "Epoch: 2, Batch: 99, Loss: 2.7777137756347656\n",
      "Generated text: \u0000isttis mear a sid yer.\n",
      "\n",
      "BRThire:\n",
      "Trpiof t. at\n",
      "Thexouceplomy se I any woke. Cl�irowiouges,\n",
      "I and thsat tlad whe hiter hi...\n",
      "Generated text: \u0000isttis mear a sid yer.\n",
      "\n",
      "BRThire:\n",
      "Trpiof t. at\n",
      "Thexouceplomy se I any woke. Cl�irowiouges,\n",
      "I and thsat tlad whe hiter hi...\n",
      "Epoch: 3, Batch: 0, Loss: 2.7805323600769043\n",
      "Epoch: 3, Batch: 0, Loss: 2.7805323600769043\n",
      "Epoch: 3, Batch: 1, Loss: 2.779061794281006\n",
      "Epoch: 3, Batch: 1, Loss: 2.779061794281006\n",
      "Epoch: 3, Batch: 2, Loss: 2.790530204772949\n",
      "Epoch: 3, Batch: 2, Loss: 2.790530204772949\n",
      "Epoch: 3, Batch: 3, Loss: 2.8209125995635986\n",
      "Epoch: 3, Batch: 3, Loss: 2.8209125995635986\n",
      "Epoch: 3, Batch: 4, Loss: 2.7771401405334473\n",
      "Epoch: 3, Batch: 4, Loss: 2.7771401405334473\n",
      "Epoch: 3, Batch: 5, Loss: 2.786407232284546\n",
      "Epoch: 3, Batch: 5, Loss: 2.786407232284546\n",
      "Epoch: 3, Batch: 6, Loss: 2.7696950435638428\n",
      "Epoch: 3, Batch: 6, Loss: 2.7696950435638428\n",
      "Epoch: 3, Batch: 7, Loss: 2.780593156814575\n",
      "Epoch: 3, Batch: 7, Loss: 2.780593156814575\n",
      "Epoch: 3, Batch: 8, Loss: 2.74359393119812\n",
      "Epoch: 3, Batch: 8, Loss: 2.74359393119812\n",
      "Epoch: 3, Batch: 9, Loss: 2.777021884918213\n",
      "Epoch: 3, Batch: 9, Loss: 2.777021884918213\n",
      "Epoch: 3, Batch: 10, Loss: 2.7781856060028076\n",
      "Epoch: 3, Batch: 10, Loss: 2.7781856060028076\n",
      "Epoch: 3, Batch: 11, Loss: 2.7880897521972656\n",
      "Epoch: 3, Batch: 11, Loss: 2.7880897521972656\n",
      "Epoch: 3, Batch: 12, Loss: 2.760636568069458\n",
      "Epoch: 3, Batch: 12, Loss: 2.760636568069458\n",
      "Epoch: 3, Batch: 13, Loss: 2.779147148132324\n",
      "Epoch: 3, Batch: 13, Loss: 2.779147148132324\n",
      "Epoch: 3, Batch: 14, Loss: 2.762341022491455\n",
      "Epoch: 3, Batch: 14, Loss: 2.762341022491455\n",
      "Epoch: 3, Batch: 15, Loss: 2.7601141929626465\n",
      "Epoch: 3, Batch: 15, Loss: 2.7601141929626465\n",
      "Epoch: 3, Batch: 16, Loss: 2.738870143890381\n",
      "Epoch: 3, Batch: 16, Loss: 2.738870143890381\n",
      "Epoch: 3, Batch: 17, Loss: 2.744074821472168\n",
      "Epoch: 3, Batch: 17, Loss: 2.744074821472168\n",
      "Epoch: 3, Batch: 18, Loss: 2.719414710998535\n",
      "Epoch: 3, Batch: 18, Loss: 2.719414710998535\n",
      "Epoch: 3, Batch: 19, Loss: 2.765575408935547\n",
      "Epoch: 3, Batch: 19, Loss: 2.765575408935547\n",
      "Epoch: 3, Batch: 20, Loss: 2.733530044555664\n",
      "Epoch: 3, Batch: 20, Loss: 2.733530044555664\n",
      "Epoch: 3, Batch: 21, Loss: 2.813201904296875\n",
      "Epoch: 3, Batch: 21, Loss: 2.813201904296875\n",
      "Epoch: 3, Batch: 22, Loss: 2.8752174377441406\n",
      "Epoch: 3, Batch: 22, Loss: 2.8752174377441406\n",
      "Epoch: 3, Batch: 23, Loss: 2.8202664852142334\n",
      "Epoch: 3, Batch: 23, Loss: 2.8202664852142334\n",
      "Epoch: 3, Batch: 24, Loss: 2.7899794578552246\n",
      "Epoch: 3, Batch: 24, Loss: 2.7899794578552246\n",
      "Epoch: 3, Batch: 25, Loss: 2.805043935775757\n",
      "Epoch: 3, Batch: 25, Loss: 2.805043935775757\n",
      "Epoch: 3, Batch: 26, Loss: 2.766312599182129\n",
      "Epoch: 3, Batch: 26, Loss: 2.766312599182129\n",
      "Epoch: 3, Batch: 27, Loss: 2.7643396854400635\n",
      "Epoch: 3, Batch: 27, Loss: 2.7643396854400635\n",
      "Epoch: 3, Batch: 28, Loss: 2.7755775451660156\n",
      "Epoch: 3, Batch: 28, Loss: 2.7755775451660156\n",
      "Epoch: 3, Batch: 29, Loss: 2.780832052230835\n",
      "Epoch: 3, Batch: 29, Loss: 2.780832052230835\n",
      "Epoch: 3, Batch: 30, Loss: 2.789106845855713\n",
      "Epoch: 3, Batch: 30, Loss: 2.789106845855713\n",
      "Epoch: 3, Batch: 31, Loss: 2.7645201683044434\n",
      "Epoch: 3, Batch: 31, Loss: 2.7645201683044434\n",
      "Epoch: 3, Batch: 32, Loss: 2.7351717948913574\n",
      "Epoch: 3, Batch: 32, Loss: 2.7351717948913574\n",
      "Epoch: 3, Batch: 33, Loss: 2.7690670490264893\n",
      "Epoch: 3, Batch: 33, Loss: 2.7690670490264893\n",
      "Epoch: 3, Batch: 34, Loss: 2.7662782669067383\n",
      "Epoch: 3, Batch: 34, Loss: 2.7662782669067383\n",
      "Epoch: 3, Batch: 35, Loss: 2.7397642135620117\n",
      "Epoch: 3, Batch: 35, Loss: 2.7397642135620117\n",
      "Epoch: 3, Batch: 36, Loss: 2.7210919857025146\n",
      "Epoch: 3, Batch: 36, Loss: 2.7210919857025146\n",
      "Epoch: 3, Batch: 37, Loss: 2.733336925506592\n",
      "Epoch: 3, Batch: 37, Loss: 2.733336925506592\n",
      "Epoch: 3, Batch: 38, Loss: 2.7264788150787354\n",
      "Epoch: 3, Batch: 38, Loss: 2.7264788150787354\n",
      "Epoch: 3, Batch: 39, Loss: 2.7525856494903564\n",
      "Epoch: 3, Batch: 39, Loss: 2.7525856494903564\n",
      "Epoch: 3, Batch: 40, Loss: 2.7345852851867676\n",
      "Epoch: 3, Batch: 40, Loss: 2.7345852851867676\n",
      "Epoch: 3, Batch: 41, Loss: 2.7398386001586914\n",
      "Epoch: 3, Batch: 41, Loss: 2.7398386001586914\n",
      "Epoch: 3, Batch: 42, Loss: 2.771610975265503\n",
      "Epoch: 3, Batch: 42, Loss: 2.771610975265503\n",
      "Epoch: 3, Batch: 43, Loss: 2.7974987030029297\n",
      "Epoch: 3, Batch: 43, Loss: 2.7974987030029297\n",
      "Epoch: 3, Batch: 44, Loss: 2.721233367919922\n",
      "Epoch: 3, Batch: 44, Loss: 2.721233367919922\n",
      "Epoch: 3, Batch: 45, Loss: 2.736145257949829\n",
      "Epoch: 3, Batch: 45, Loss: 2.736145257949829\n",
      "Epoch: 3, Batch: 46, Loss: 2.7592062950134277\n",
      "Epoch: 3, Batch: 46, Loss: 2.7592062950134277\n",
      "Epoch: 3, Batch: 47, Loss: 2.745303153991699\n",
      "Epoch: 3, Batch: 47, Loss: 2.745303153991699\n",
      "Epoch: 3, Batch: 48, Loss: 2.719982147216797\n",
      "Epoch: 3, Batch: 48, Loss: 2.719982147216797\n",
      "Epoch: 3, Batch: 49, Loss: 2.7145984172821045\n",
      "Epoch: 3, Batch: 49, Loss: 2.7145984172821045\n",
      "Epoch: 3, Batch: 50, Loss: 2.7251501083374023\n",
      "Epoch: 3, Batch: 50, Loss: 2.7251501083374023\n",
      "Epoch: 3, Batch: 51, Loss: 2.699455738067627\n",
      "Epoch: 3, Batch: 51, Loss: 2.699455738067627\n",
      "Epoch: 3, Batch: 52, Loss: 2.7203924655914307\n",
      "Epoch: 3, Batch: 52, Loss: 2.7203924655914307\n",
      "Epoch: 3, Batch: 53, Loss: 2.710451602935791\n",
      "Epoch: 3, Batch: 53, Loss: 2.710451602935791\n",
      "Epoch: 3, Batch: 54, Loss: 2.6900174617767334\n",
      "Epoch: 3, Batch: 54, Loss: 2.6900174617767334\n",
      "Epoch: 3, Batch: 55, Loss: 2.660677433013916\n",
      "Epoch: 3, Batch: 55, Loss: 2.660677433013916\n",
      "Epoch: 3, Batch: 56, Loss: 2.699902057647705\n",
      "Epoch: 3, Batch: 56, Loss: 2.699902057647705\n",
      "Epoch: 3, Batch: 57, Loss: 2.710073709487915\n",
      "Epoch: 3, Batch: 57, Loss: 2.710073709487915\n",
      "Epoch: 3, Batch: 58, Loss: 2.692148208618164\n",
      "Epoch: 3, Batch: 58, Loss: 2.692148208618164\n",
      "Epoch: 3, Batch: 59, Loss: 2.72243595123291\n",
      "Epoch: 3, Batch: 59, Loss: 2.72243595123291\n",
      "Epoch: 3, Batch: 60, Loss: 2.677334785461426\n",
      "Epoch: 3, Batch: 60, Loss: 2.677334785461426\n",
      "Epoch: 3, Batch: 61, Loss: 2.6924514770507812\n",
      "Epoch: 3, Batch: 61, Loss: 2.6924514770507812\n",
      "Epoch: 3, Batch: 62, Loss: 2.709106683731079\n",
      "Epoch: 3, Batch: 62, Loss: 2.709106683731079\n",
      "Epoch: 3, Batch: 63, Loss: 2.6998608112335205\n",
      "Epoch: 3, Batch: 63, Loss: 2.6998608112335205\n",
      "Epoch: 3, Batch: 64, Loss: 2.6887106895446777\n",
      "Epoch: 3, Batch: 64, Loss: 2.6887106895446777\n",
      "Epoch: 3, Batch: 65, Loss: 2.6811347007751465\n",
      "Epoch: 3, Batch: 65, Loss: 2.6811347007751465\n",
      "Epoch: 3, Batch: 66, Loss: 2.728022575378418\n",
      "Epoch: 3, Batch: 66, Loss: 2.728022575378418\n",
      "Epoch: 3, Batch: 67, Loss: 2.6581268310546875\n",
      "Epoch: 3, Batch: 67, Loss: 2.6581268310546875\n",
      "Epoch: 3, Batch: 68, Loss: 2.6703948974609375\n",
      "Epoch: 3, Batch: 68, Loss: 2.6703948974609375\n",
      "Epoch: 3, Batch: 69, Loss: 2.684112548828125\n",
      "Epoch: 3, Batch: 69, Loss: 2.684112548828125\n",
      "Epoch: 3, Batch: 70, Loss: 2.6694717407226562\n",
      "Epoch: 3, Batch: 70, Loss: 2.6694717407226562\n",
      "Epoch: 3, Batch: 71, Loss: 2.679600715637207\n",
      "Epoch: 3, Batch: 71, Loss: 2.679600715637207\n",
      "Epoch: 3, Batch: 72, Loss: 2.6326608657836914\n",
      "Epoch: 3, Batch: 72, Loss: 2.6326608657836914\n",
      "Epoch: 3, Batch: 73, Loss: 2.6507129669189453\n",
      "Epoch: 3, Batch: 73, Loss: 2.6507129669189453\n",
      "Epoch: 3, Batch: 74, Loss: 2.658647060394287\n",
      "Epoch: 3, Batch: 74, Loss: 2.658647060394287\n",
      "Epoch: 3, Batch: 75, Loss: 2.654378652572632\n",
      "Epoch: 3, Batch: 75, Loss: 2.654378652572632\n",
      "Epoch: 3, Batch: 76, Loss: 2.63291072845459\n",
      "Epoch: 3, Batch: 76, Loss: 2.63291072845459\n",
      "Epoch: 3, Batch: 77, Loss: 2.6273488998413086\n",
      "Epoch: 3, Batch: 77, Loss: 2.6273488998413086\n",
      "Epoch: 3, Batch: 78, Loss: 2.642613410949707\n",
      "Epoch: 3, Batch: 78, Loss: 2.642613410949707\n",
      "Epoch: 3, Batch: 79, Loss: 2.640756130218506\n",
      "Epoch: 3, Batch: 79, Loss: 2.640756130218506\n",
      "Epoch: 3, Batch: 80, Loss: 2.6384196281433105\n",
      "Epoch: 3, Batch: 80, Loss: 2.6384196281433105\n",
      "Epoch: 3, Batch: 81, Loss: 2.74100923538208\n",
      "Epoch: 3, Batch: 81, Loss: 2.74100923538208\n",
      "Epoch: 3, Batch: 82, Loss: 2.718881607055664\n",
      "Epoch: 3, Batch: 82, Loss: 2.718881607055664\n",
      "Epoch: 3, Batch: 83, Loss: 2.7079484462738037\n",
      "Epoch: 3, Batch: 83, Loss: 2.7079484462738037\n",
      "Epoch: 3, Batch: 84, Loss: 2.670558452606201\n",
      "Epoch: 3, Batch: 84, Loss: 2.670558452606201\n",
      "Epoch: 3, Batch: 85, Loss: 2.695880174636841\n",
      "Epoch: 3, Batch: 85, Loss: 2.695880174636841\n",
      "Epoch: 3, Batch: 86, Loss: 2.6724815368652344\n",
      "Epoch: 3, Batch: 86, Loss: 2.6724815368652344\n",
      "Epoch: 3, Batch: 87, Loss: 2.6450395584106445\n",
      "Epoch: 3, Batch: 87, Loss: 2.6450395584106445\n",
      "Epoch: 3, Batch: 88, Loss: 2.625430107116699\n",
      "Epoch: 3, Batch: 88, Loss: 2.625430107116699\n",
      "Epoch: 3, Batch: 89, Loss: 2.6355674266815186\n",
      "Epoch: 3, Batch: 89, Loss: 2.6355674266815186\n",
      "Epoch: 3, Batch: 90, Loss: 2.638962745666504\n",
      "Epoch: 3, Batch: 90, Loss: 2.638962745666504\n",
      "Epoch: 3, Batch: 91, Loss: 2.611794948577881\n",
      "Epoch: 3, Batch: 91, Loss: 2.611794948577881\n",
      "Epoch: 3, Batch: 92, Loss: 2.6425461769104004\n",
      "Epoch: 3, Batch: 92, Loss: 2.6425461769104004\n",
      "Epoch: 3, Batch: 93, Loss: 2.5961995124816895\n",
      "Epoch: 3, Batch: 93, Loss: 2.5961995124816895\n",
      "Epoch: 3, Batch: 94, Loss: 2.6033201217651367\n",
      "Epoch: 3, Batch: 94, Loss: 2.6033201217651367\n",
      "Epoch: 3, Batch: 95, Loss: 2.622236728668213\n",
      "Epoch: 3, Batch: 95, Loss: 2.622236728668213\n",
      "Epoch: 3, Batch: 96, Loss: 2.587435245513916\n",
      "Epoch: 3, Batch: 96, Loss: 2.587435245513916\n",
      "Epoch: 3, Batch: 97, Loss: 2.6164121627807617\n",
      "Epoch: 3, Batch: 97, Loss: 2.6164121627807617\n",
      "Epoch: 3, Batch: 98, Loss: 2.5716195106506348\n",
      "Epoch: 3, Batch: 98, Loss: 2.5716195106506348\n",
      "Epoch: 3, Batch: 99, Loss: 2.5745978355407715\n",
      "Epoch: 3, Batch: 99, Loss: 2.5745978355407715\n",
      "Generated text: \u0000not wil, teanit crand ay did.\n",
      "\n",
      "DWANG\u0012Y:\n",
      "Warindis gra nod fa thou6ere whter aiDus I'll y?\n",
      "\n",
      "ERY:\n",
      "So:\n",
      "I anqus yeain ar�d, no atome mow...\n",
      "Generated text: \u0000not wil, teanit crand ay did.\n",
      "\n",
      "DWANG\u0012Y:\n",
      "Warindis gra nod fa thou6ere whter aiDus I'll y?\n",
      "\n",
      "ERY:\n",
      "So:\n",
      "I anqus yeain ar�d, no atome mow...\n",
      "Epoch: 4, Batch: 0, Loss: 2.59251070022583\n",
      "Epoch: 4, Batch: 0, Loss: 2.59251070022583\n",
      "Epoch: 4, Batch: 1, Loss: 2.641232490539551\n",
      "Epoch: 4, Batch: 1, Loss: 2.641232490539551\n",
      "Epoch: 4, Batch: 2, Loss: 2.6142830848693848\n",
      "Epoch: 4, Batch: 2, Loss: 2.6142830848693848\n",
      "Epoch: 4, Batch: 3, Loss: 2.647071123123169\n",
      "Epoch: 4, Batch: 3, Loss: 2.647071123123169\n",
      "Epoch: 4, Batch: 4, Loss: 2.6023054122924805\n",
      "Epoch: 4, Batch: 4, Loss: 2.6023054122924805\n",
      "Epoch: 4, Batch: 5, Loss: 2.617476224899292\n",
      "Epoch: 4, Batch: 5, Loss: 2.617476224899292\n",
      "Epoch: 4, Batch: 6, Loss: 2.5872349739074707\n",
      "Epoch: 4, Batch: 6, Loss: 2.5872349739074707\n",
      "Epoch: 4, Batch: 7, Loss: 2.623237133026123\n",
      "Epoch: 4, Batch: 7, Loss: 2.623237133026123\n",
      "Epoch: 4, Batch: 8, Loss: 2.5989770889282227\n",
      "Epoch: 4, Batch: 8, Loss: 2.5989770889282227\n",
      "Epoch: 4, Batch: 9, Loss: 2.5696754455566406\n",
      "Epoch: 4, Batch: 9, Loss: 2.5696754455566406\n",
      "Epoch: 4, Batch: 10, Loss: 2.5974602699279785\n",
      "Epoch: 4, Batch: 10, Loss: 2.5974602699279785\n",
      "Epoch: 4, Batch: 11, Loss: 2.5877561569213867\n",
      "Epoch: 4, Batch: 11, Loss: 2.5877561569213867\n",
      "Epoch: 4, Batch: 12, Loss: 2.579230308532715\n",
      "Epoch: 4, Batch: 12, Loss: 2.579230308532715\n",
      "Epoch: 4, Batch: 13, Loss: 2.545738697052002\n",
      "Epoch: 4, Batch: 13, Loss: 2.545738697052002\n",
      "Epoch: 4, Batch: 14, Loss: 2.5364809036254883\n",
      "Epoch: 4, Batch: 14, Loss: 2.5364809036254883\n",
      "Epoch: 4, Batch: 15, Loss: 2.557265520095825\n",
      "Epoch: 4, Batch: 15, Loss: 2.557265520095825\n",
      "Epoch: 4, Batch: 16, Loss: 2.5577588081359863\n",
      "Epoch: 4, Batch: 16, Loss: 2.5577588081359863\n",
      "Epoch: 4, Batch: 17, Loss: 2.55172061920166\n",
      "Epoch: 4, Batch: 17, Loss: 2.55172061920166\n",
      "Epoch: 4, Batch: 18, Loss: 2.552227258682251\n",
      "Epoch: 4, Batch: 18, Loss: 2.552227258682251\n",
      "Epoch: 4, Batch: 19, Loss: 2.5339889526367188\n",
      "Epoch: 4, Batch: 19, Loss: 2.5339889526367188\n",
      "Epoch: 4, Batch: 20, Loss: 2.5325393676757812\n",
      "Epoch: 4, Batch: 20, Loss: 2.5325393676757812\n",
      "Epoch: 4, Batch: 21, Loss: 2.6257991790771484\n",
      "Epoch: 4, Batch: 21, Loss: 2.6257991790771484\n",
      "Epoch: 4, Batch: 22, Loss: 2.5605406761169434\n",
      "Epoch: 4, Batch: 22, Loss: 2.5605406761169434\n",
      "Epoch: 4, Batch: 23, Loss: 2.5791797637939453\n",
      "Epoch: 4, Batch: 23, Loss: 2.5791797637939453\n",
      "Epoch: 4, Batch: 24, Loss: 2.5986623764038086\n",
      "Epoch: 4, Batch: 24, Loss: 2.5986623764038086\n",
      "Epoch: 4, Batch: 25, Loss: 2.558241844177246\n",
      "Epoch: 4, Batch: 25, Loss: 2.558241844177246\n",
      "Epoch: 4, Batch: 26, Loss: 2.5715954303741455\n",
      "Epoch: 4, Batch: 26, Loss: 2.5715954303741455\n",
      "Epoch: 4, Batch: 27, Loss: 2.543386459350586\n",
      "Epoch: 4, Batch: 27, Loss: 2.543386459350586\n",
      "Epoch: 4, Batch: 28, Loss: 2.5254006385803223\n",
      "Epoch: 4, Batch: 28, Loss: 2.5254006385803223\n",
      "Epoch: 4, Batch: 29, Loss: 2.5373072624206543\n",
      "Epoch: 4, Batch: 29, Loss: 2.5373072624206543\n",
      "Epoch: 4, Batch: 30, Loss: 2.495208263397217\n",
      "Epoch: 4, Batch: 30, Loss: 2.495208263397217\n",
      "Epoch: 4, Batch: 31, Loss: 2.5290775299072266\n",
      "Epoch: 4, Batch: 31, Loss: 2.5290775299072266\n",
      "Epoch: 4, Batch: 32, Loss: 2.529085636138916\n",
      "Epoch: 4, Batch: 32, Loss: 2.529085636138916\n",
      "Epoch: 4, Batch: 33, Loss: 2.500999927520752\n",
      "Epoch: 4, Batch: 33, Loss: 2.500999927520752\n",
      "Epoch: 4, Batch: 34, Loss: 2.50814151763916\n",
      "Epoch: 4, Batch: 34, Loss: 2.50814151763916\n",
      "Epoch: 4, Batch: 35, Loss: 2.5228145122528076\n",
      "Epoch: 4, Batch: 35, Loss: 2.5228145122528076\n",
      "Epoch: 4, Batch: 36, Loss: 2.5141916275024414\n",
      "Epoch: 4, Batch: 36, Loss: 2.5141916275024414\n",
      "Epoch: 4, Batch: 37, Loss: 2.5091123580932617\n",
      "Epoch: 4, Batch: 37, Loss: 2.5091123580932617\n",
      "Epoch: 4, Batch: 38, Loss: 2.5194313526153564\n",
      "Epoch: 4, Batch: 38, Loss: 2.5194313526153564\n",
      "Epoch: 4, Batch: 39, Loss: 2.4668283462524414\n",
      "Epoch: 4, Batch: 39, Loss: 2.4668283462524414\n",
      "Epoch: 4, Batch: 40, Loss: 2.5198774337768555\n",
      "Epoch: 4, Batch: 40, Loss: 2.5198774337768555\n",
      "Epoch: 4, Batch: 41, Loss: 2.569391965866089\n",
      "Epoch: 4, Batch: 41, Loss: 2.569391965866089\n",
      "Epoch: 4, Batch: 42, Loss: 2.515822410583496\n",
      "Epoch: 4, Batch: 42, Loss: 2.515822410583496\n",
      "Epoch: 4, Batch: 43, Loss: 2.519113540649414\n",
      "Epoch: 4, Batch: 43, Loss: 2.519113540649414\n",
      "Epoch: 4, Batch: 44, Loss: 2.5153510570526123\n",
      "Epoch: 4, Batch: 44, Loss: 2.5153510570526123\n",
      "Epoch: 4, Batch: 45, Loss: 2.506159782409668\n",
      "Epoch: 4, Batch: 45, Loss: 2.506159782409668\n",
      "Epoch: 4, Batch: 46, Loss: 2.5071349143981934\n",
      "Epoch: 4, Batch: 46, Loss: 2.5071349143981934\n",
      "Epoch: 4, Batch: 47, Loss: 2.482530355453491\n",
      "Epoch: 4, Batch: 47, Loss: 2.482530355453491\n",
      "Epoch: 4, Batch: 48, Loss: 2.4704084396362305\n",
      "Epoch: 4, Batch: 48, Loss: 2.4704084396362305\n",
      "Epoch: 4, Batch: 49, Loss: 2.488588333129883\n",
      "Epoch: 4, Batch: 49, Loss: 2.488588333129883\n",
      "Epoch: 4, Batch: 50, Loss: 2.4510092735290527\n",
      "Epoch: 4, Batch: 50, Loss: 2.4510092735290527\n",
      "Epoch: 4, Batch: 51, Loss: 2.451343536376953\n",
      "Epoch: 4, Batch: 51, Loss: 2.451343536376953\n",
      "Epoch: 4, Batch: 52, Loss: 2.4926137924194336\n",
      "Epoch: 4, Batch: 52, Loss: 2.4926137924194336\n",
      "Epoch: 4, Batch: 53, Loss: 2.4684243202209473\n",
      "Epoch: 4, Batch: 53, Loss: 2.4684243202209473\n",
      "Epoch: 4, Batch: 54, Loss: 2.4549105167388916\n",
      "Epoch: 4, Batch: 54, Loss: 2.4549105167388916\n",
      "Epoch: 4, Batch: 55, Loss: 2.4508473873138428\n",
      "Epoch: 4, Batch: 55, Loss: 2.4508473873138428\n",
      "Epoch: 4, Batch: 56, Loss: 2.4288992881774902\n",
      "Epoch: 4, Batch: 56, Loss: 2.4288992881774902\n",
      "Epoch: 4, Batch: 57, Loss: 2.465261459350586\n",
      "Epoch: 4, Batch: 57, Loss: 2.465261459350586\n",
      "Epoch: 4, Batch: 58, Loss: 2.469782829284668\n",
      "Epoch: 4, Batch: 58, Loss: 2.469782829284668\n",
      "Epoch: 4, Batch: 59, Loss: 2.455641508102417\n",
      "Epoch: 4, Batch: 59, Loss: 2.455641508102417\n",
      "Epoch: 4, Batch: 60, Loss: 2.4761366844177246\n",
      "Epoch: 4, Batch: 60, Loss: 2.4761366844177246\n",
      "Epoch: 4, Batch: 61, Loss: 2.565514087677002\n",
      "Epoch: 4, Batch: 61, Loss: 2.565514087677002\n",
      "Epoch: 4, Batch: 62, Loss: 2.503901720046997\n",
      "Epoch: 4, Batch: 62, Loss: 2.503901720046997\n",
      "Epoch: 4, Batch: 63, Loss: 2.5394792556762695\n",
      "Epoch: 4, Batch: 63, Loss: 2.5394792556762695\n",
      "Epoch: 4, Batch: 64, Loss: 2.471731662750244\n",
      "Epoch: 4, Batch: 64, Loss: 2.471731662750244\n",
      "Epoch: 4, Batch: 65, Loss: 2.4918346405029297\n",
      "Epoch: 4, Batch: 65, Loss: 2.4918346405029297\n",
      "Epoch: 4, Batch: 66, Loss: 2.473036766052246\n",
      "Epoch: 4, Batch: 66, Loss: 2.473036766052246\n",
      "Epoch: 4, Batch: 67, Loss: 2.4726293087005615\n",
      "Epoch: 4, Batch: 67, Loss: 2.4726293087005615\n",
      "Epoch: 4, Batch: 68, Loss: 2.486581325531006\n",
      "Epoch: 4, Batch: 68, Loss: 2.486581325531006\n",
      "Epoch: 4, Batch: 69, Loss: 2.464850902557373\n",
      "Epoch: 4, Batch: 69, Loss: 2.464850902557373\n",
      "Epoch: 4, Batch: 70, Loss: 2.478484630584717\n",
      "Epoch: 4, Batch: 70, Loss: 2.478484630584717\n",
      "Epoch: 4, Batch: 71, Loss: 2.4191701412200928\n",
      "Epoch: 4, Batch: 71, Loss: 2.4191701412200928\n",
      "Epoch: 4, Batch: 72, Loss: 2.4243383407592773\n",
      "Epoch: 4, Batch: 72, Loss: 2.4243383407592773\n",
      "Epoch: 4, Batch: 73, Loss: 2.429692268371582\n",
      "Epoch: 4, Batch: 73, Loss: 2.429692268371582\n",
      "Epoch: 4, Batch: 74, Loss: 2.4274816513061523\n",
      "Epoch: 4, Batch: 74, Loss: 2.4274816513061523\n",
      "Epoch: 4, Batch: 75, Loss: 2.4131627082824707\n",
      "Epoch: 4, Batch: 75, Loss: 2.4131627082824707\n",
      "Epoch: 4, Batch: 76, Loss: 2.4181885719299316\n",
      "Epoch: 4, Batch: 76, Loss: 2.4181885719299316\n",
      "Epoch: 4, Batch: 77, Loss: 2.4133238792419434\n",
      "Epoch: 4, Batch: 77, Loss: 2.4133238792419434\n",
      "Epoch: 4, Batch: 78, Loss: 2.3947067260742188\n",
      "Epoch: 4, Batch: 78, Loss: 2.3947067260742188\n",
      "Epoch: 4, Batch: 79, Loss: 2.4246318340301514\n",
      "Epoch: 4, Batch: 79, Loss: 2.4246318340301514\n",
      "Epoch: 4, Batch: 80, Loss: 2.4127445220947266\n",
      "Epoch: 4, Batch: 80, Loss: 2.4127445220947266\n",
      "Epoch: 4, Batch: 81, Loss: 2.5060064792633057\n",
      "Epoch: 4, Batch: 81, Loss: 2.5060064792633057\n",
      "Epoch: 4, Batch: 82, Loss: 2.4742414951324463\n",
      "Epoch: 4, Batch: 82, Loss: 2.4742414951324463\n",
      "Epoch: 4, Batch: 83, Loss: 2.4382588863372803\n",
      "Epoch: 4, Batch: 83, Loss: 2.4382588863372803\n",
      "Epoch: 4, Batch: 84, Loss: 2.476808547973633\n",
      "Epoch: 4, Batch: 84, Loss: 2.476808547973633\n",
      "Epoch: 4, Batch: 85, Loss: 2.4394097328186035\n",
      "Epoch: 4, Batch: 85, Loss: 2.4394097328186035\n",
      "Epoch: 4, Batch: 86, Loss: 2.4615769386291504\n",
      "Epoch: 4, Batch: 86, Loss: 2.4615769386291504\n",
      "Epoch: 4, Batch: 87, Loss: 2.430201530456543\n",
      "Epoch: 4, Batch: 87, Loss: 2.430201530456543\n",
      "Epoch: 4, Batch: 88, Loss: 2.436821937561035\n",
      "Epoch: 4, Batch: 88, Loss: 2.436821937561035\n",
      "Epoch: 4, Batch: 89, Loss: 2.3967843055725098\n",
      "Epoch: 4, Batch: 89, Loss: 2.3967843055725098\n",
      "Epoch: 4, Batch: 90, Loss: 2.387416362762451\n",
      "Epoch: 4, Batch: 90, Loss: 2.387416362762451\n",
      "Epoch: 4, Batch: 91, Loss: 2.350240707397461\n",
      "Epoch: 4, Batch: 91, Loss: 2.350240707397461\n",
      "Epoch: 4, Batch: 92, Loss: 2.416846513748169\n",
      "Epoch: 4, Batch: 92, Loss: 2.416846513748169\n",
      "Epoch: 4, Batch: 93, Loss: 2.402620315551758\n",
      "Epoch: 4, Batch: 93, Loss: 2.402620315551758\n",
      "Epoch: 4, Batch: 94, Loss: 2.3672642707824707\n",
      "Epoch: 4, Batch: 94, Loss: 2.3672642707824707\n",
      "Epoch: 4, Batch: 95, Loss: 2.3883309364318848\n",
      "Epoch: 4, Batch: 95, Loss: 2.3883309364318848\n",
      "Epoch: 4, Batch: 96, Loss: 2.3461217880249023\n",
      "Epoch: 4, Batch: 96, Loss: 2.3461217880249023\n",
      "Epoch: 4, Batch: 97, Loss: 2.341695785522461\n",
      "Epoch: 4, Batch: 97, Loss: 2.341695785522461\n",
      "Epoch: 4, Batch: 98, Loss: 2.341961145401001\n",
      "Epoch: 4, Batch: 98, Loss: 2.341961145401001\n",
      "Epoch: 4, Batch: 99, Loss: 2.3617467880249023\n",
      "Epoch: 4, Batch: 99, Loss: 2.3617467880249023\n",
      "Generated text: \u0000 you lideful.:\n",
      "The eay dealdling Came you king untancro�s\n",
      "Oul-call; leantorle se'�'s of lanceld,\n",
      "She's wild make pecus...\n",
      "Generated text: \u0000 you lideful.:\n",
      "The eay dealdling Came you king untancro�s\n",
      "Oul-call; leantorle se'�'s of lanceld,\n",
      "She's wild make pecus...\n",
      "Epoch: 5, Batch: 0, Loss: 2.3730740547180176\n",
      "Epoch: 5, Batch: 0, Loss: 2.3730740547180176\n",
      "Epoch: 5, Batch: 1, Loss: 2.4564208984375\n",
      "Epoch: 5, Batch: 1, Loss: 2.4564208984375\n",
      "Epoch: 5, Batch: 2, Loss: 2.403557538986206\n",
      "Epoch: 5, Batch: 2, Loss: 2.403557538986206\n",
      "Epoch: 5, Batch: 3, Loss: 2.3939743041992188\n",
      "Epoch: 5, Batch: 3, Loss: 2.3939743041992188\n",
      "Epoch: 5, Batch: 4, Loss: 2.4126057624816895\n",
      "Epoch: 5, Batch: 4, Loss: 2.4126057624816895\n",
      "Epoch: 5, Batch: 5, Loss: 2.3787684440612793\n",
      "Epoch: 5, Batch: 5, Loss: 2.3787684440612793\n",
      "Epoch: 5, Batch: 6, Loss: 2.381554126739502\n",
      "Epoch: 5, Batch: 6, Loss: 2.381554126739502\n",
      "Epoch: 5, Batch: 7, Loss: 2.3749537467956543\n",
      "Epoch: 5, Batch: 7, Loss: 2.3749537467956543\n",
      "Epoch: 5, Batch: 8, Loss: 2.334671974182129\n",
      "Epoch: 5, Batch: 8, Loss: 2.334671974182129\n",
      "Epoch: 5, Batch: 9, Loss: 2.357921600341797\n",
      "Epoch: 5, Batch: 9, Loss: 2.357921600341797\n",
      "Epoch: 5, Batch: 10, Loss: 2.3895483016967773\n",
      "Epoch: 5, Batch: 10, Loss: 2.3895483016967773\n",
      "Epoch: 5, Batch: 11, Loss: 2.376659870147705\n",
      "Epoch: 5, Batch: 11, Loss: 2.376659870147705\n",
      "Epoch: 5, Batch: 12, Loss: 2.35455322265625\n",
      "Epoch: 5, Batch: 12, Loss: 2.35455322265625\n",
      "Epoch: 5, Batch: 13, Loss: 2.3409652709960938\n",
      "Epoch: 5, Batch: 13, Loss: 2.3409652709960938\n",
      "Epoch: 5, Batch: 14, Loss: 2.381588935852051\n",
      "Epoch: 5, Batch: 14, Loss: 2.381588935852051\n",
      "Epoch: 5, Batch: 15, Loss: 2.365262508392334\n",
      "Epoch: 5, Batch: 15, Loss: 2.365262508392334\n",
      "Epoch: 5, Batch: 16, Loss: 2.336867332458496\n",
      "Epoch: 5, Batch: 16, Loss: 2.336867332458496\n",
      "Epoch: 5, Batch: 17, Loss: 2.2964961528778076\n",
      "Epoch: 5, Batch: 17, Loss: 2.2964961528778076\n",
      "Epoch: 5, Batch: 18, Loss: 2.339419364929199\n",
      "Epoch: 5, Batch: 18, Loss: 2.339419364929199\n",
      "Epoch: 5, Batch: 19, Loss: 2.3101744651794434\n",
      "Epoch: 5, Batch: 19, Loss: 2.3101744651794434\n",
      "Epoch: 5, Batch: 20, Loss: 2.3108105659484863\n",
      "Epoch: 5, Batch: 20, Loss: 2.3108105659484863\n",
      "Epoch: 5, Batch: 21, Loss: 2.3179569244384766\n",
      "Epoch: 5, Batch: 21, Loss: 2.3179569244384766\n",
      "Epoch: 5, Batch: 22, Loss: 2.3790860176086426\n",
      "Epoch: 5, Batch: 22, Loss: 2.3790860176086426\n",
      "Epoch: 5, Batch: 23, Loss: 2.3640737533569336\n",
      "Epoch: 5, Batch: 23, Loss: 2.3640737533569336\n",
      "Epoch: 5, Batch: 24, Loss: 2.355618476867676\n",
      "Epoch: 5, Batch: 24, Loss: 2.355618476867676\n",
      "Epoch: 5, Batch: 25, Loss: 2.374190330505371\n",
      "Epoch: 5, Batch: 25, Loss: 2.374190330505371\n",
      "Epoch: 5, Batch: 26, Loss: 2.342411756515503\n",
      "Epoch: 5, Batch: 26, Loss: 2.342411756515503\n",
      "Epoch: 5, Batch: 27, Loss: 2.3357999324798584\n",
      "Epoch: 5, Batch: 27, Loss: 2.3357999324798584\n",
      "Epoch: 5, Batch: 28, Loss: 2.346874475479126\n",
      "Epoch: 5, Batch: 28, Loss: 2.346874475479126\n",
      "Epoch: 5, Batch: 29, Loss: 2.3343820571899414\n",
      "Epoch: 5, Batch: 29, Loss: 2.3343820571899414\n",
      "Epoch: 5, Batch: 30, Loss: 2.2854392528533936\n",
      "Epoch: 5, Batch: 30, Loss: 2.2854392528533936\n",
      "Epoch: 5, Batch: 31, Loss: 2.3447000980377197\n",
      "Epoch: 5, Batch: 31, Loss: 2.3447000980377197\n",
      "Epoch: 5, Batch: 32, Loss: 2.321920394897461\n",
      "Epoch: 5, Batch: 32, Loss: 2.321920394897461\n",
      "Epoch: 5, Batch: 33, Loss: 2.2831718921661377\n",
      "Epoch: 5, Batch: 33, Loss: 2.2831718921661377\n",
      "Epoch: 5, Batch: 34, Loss: 2.2892212867736816\n",
      "Epoch: 5, Batch: 34, Loss: 2.2892212867736816\n",
      "Epoch: 5, Batch: 35, Loss: 2.2975897789001465\n",
      "Epoch: 5, Batch: 35, Loss: 2.2975897789001465\n",
      "Epoch: 5, Batch: 36, Loss: 2.276308536529541\n",
      "Epoch: 5, Batch: 36, Loss: 2.276308536529541\n",
      "Epoch: 5, Batch: 37, Loss: 2.2820394039154053\n",
      "Epoch: 5, Batch: 37, Loss: 2.2820394039154053\n",
      "Epoch: 5, Batch: 38, Loss: 2.328186511993408\n",
      "Epoch: 5, Batch: 38, Loss: 2.328186511993408\n",
      "Epoch: 5, Batch: 39, Loss: 2.295478105545044\n",
      "Epoch: 5, Batch: 39, Loss: 2.295478105545044\n",
      "Epoch: 5, Batch: 40, Loss: 2.289987564086914\n",
      "Epoch: 5, Batch: 40, Loss: 2.289987564086914\n",
      "Epoch: 5, Batch: 41, Loss: 2.414109706878662\n",
      "Epoch: 5, Batch: 41, Loss: 2.414109706878662\n",
      "Epoch: 5, Batch: 42, Loss: 2.308799982070923\n",
      "Epoch: 5, Batch: 42, Loss: 2.308799982070923\n",
      "Epoch: 5, Batch: 43, Loss: 2.3532657623291016\n",
      "Epoch: 5, Batch: 43, Loss: 2.3532657623291016\n",
      "Epoch: 5, Batch: 44, Loss: 2.286856174468994\n",
      "Epoch: 5, Batch: 44, Loss: 2.286856174468994\n",
      "Epoch: 5, Batch: 45, Loss: 2.289325714111328\n",
      "Epoch: 5, Batch: 45, Loss: 2.289325714111328\n",
      "Epoch: 5, Batch: 46, Loss: 2.2839508056640625\n",
      "Epoch: 5, Batch: 46, Loss: 2.2839508056640625\n",
      "Epoch: 5, Batch: 47, Loss: 2.3320868015289307\n",
      "Epoch: 5, Batch: 47, Loss: 2.3320868015289307\n",
      "Epoch: 5, Batch: 48, Loss: 2.275646209716797\n",
      "Epoch: 5, Batch: 48, Loss: 2.275646209716797\n",
      "Epoch: 5, Batch: 49, Loss: 2.2559409141540527\n",
      "Epoch: 5, Batch: 49, Loss: 2.2559409141540527\n",
      "Epoch: 5, Batch: 50, Loss: 2.285290002822876\n",
      "Epoch: 5, Batch: 50, Loss: 2.285290002822876\n",
      "Epoch: 5, Batch: 51, Loss: 2.2777457237243652\n",
      "Epoch: 5, Batch: 51, Loss: 2.2777457237243652\n",
      "Epoch: 5, Batch: 52, Loss: 2.2873287200927734\n",
      "Epoch: 5, Batch: 52, Loss: 2.2873287200927734\n",
      "Epoch: 5, Batch: 53, Loss: 2.287426233291626\n",
      "Epoch: 5, Batch: 53, Loss: 2.287426233291626\n",
      "Epoch: 5, Batch: 54, Loss: 2.2834458351135254\n",
      "Epoch: 5, Batch: 54, Loss: 2.2834458351135254\n",
      "Epoch: 5, Batch: 55, Loss: 2.2754812240600586\n",
      "Epoch: 5, Batch: 55, Loss: 2.2754812240600586\n",
      "Epoch: 5, Batch: 56, Loss: 2.2886769771575928\n",
      "Epoch: 5, Batch: 56, Loss: 2.2886769771575928\n",
      "Epoch: 5, Batch: 57, Loss: 2.2691643238067627\n",
      "Epoch: 5, Batch: 57, Loss: 2.2691643238067627\n",
      "Epoch: 5, Batch: 58, Loss: 2.284580945968628\n",
      "Epoch: 5, Batch: 58, Loss: 2.284580945968628\n",
      "Epoch: 5, Batch: 59, Loss: 2.2808895111083984\n",
      "Epoch: 5, Batch: 59, Loss: 2.2808895111083984\n",
      "Epoch: 5, Batch: 60, Loss: 2.275900363922119\n",
      "Epoch: 5, Batch: 60, Loss: 2.275900363922119\n",
      "Epoch: 5, Batch: 61, Loss: 2.289031982421875\n",
      "Epoch: 5, Batch: 61, Loss: 2.289031982421875\n",
      "Epoch: 5, Batch: 62, Loss: 2.248891592025757\n",
      "Epoch: 5, Batch: 62, Loss: 2.248891592025757\n",
      "Epoch: 5, Batch: 63, Loss: 2.3063597679138184\n",
      "Epoch: 5, Batch: 63, Loss: 2.3063597679138184\n",
      "Epoch: 5, Batch: 64, Loss: 2.282696485519409\n",
      "Epoch: 5, Batch: 64, Loss: 2.282696485519409\n",
      "Epoch: 5, Batch: 65, Loss: 2.2520036697387695\n",
      "Epoch: 5, Batch: 65, Loss: 2.2520036697387695\n",
      "Epoch: 5, Batch: 66, Loss: 2.316882848739624\n",
      "Epoch: 5, Batch: 66, Loss: 2.316882848739624\n",
      "Epoch: 5, Batch: 67, Loss: 2.2706422805786133\n",
      "Epoch: 5, Batch: 67, Loss: 2.2706422805786133\n",
      "Epoch: 5, Batch: 68, Loss: 2.2727062702178955\n",
      "Epoch: 5, Batch: 68, Loss: 2.2727062702178955\n",
      "Epoch: 5, Batch: 69, Loss: 2.2805376052856445\n",
      "Epoch: 5, Batch: 69, Loss: 2.2805376052856445\n",
      "Epoch: 5, Batch: 70, Loss: 2.2276930809020996\n",
      "Epoch: 5, Batch: 70, Loss: 2.2276930809020996\n",
      "Epoch: 5, Batch: 71, Loss: 2.2505435943603516\n",
      "Epoch: 5, Batch: 71, Loss: 2.2505435943603516\n",
      "Epoch: 5, Batch: 72, Loss: 2.2483906745910645\n",
      "Epoch: 5, Batch: 72, Loss: 2.2483906745910645\n",
      "Epoch: 5, Batch: 73, Loss: 2.214017391204834\n",
      "Epoch: 5, Batch: 73, Loss: 2.214017391204834\n",
      "Epoch: 5, Batch: 74, Loss: 2.19632625579834\n",
      "Epoch: 5, Batch: 74, Loss: 2.19632625579834\n",
      "Epoch: 5, Batch: 75, Loss: 2.227611541748047\n",
      "Epoch: 5, Batch: 75, Loss: 2.227611541748047\n",
      "Epoch: 5, Batch: 76, Loss: 2.2055153846740723\n",
      "Epoch: 5, Batch: 76, Loss: 2.2055153846740723\n",
      "Epoch: 5, Batch: 77, Loss: 2.2561933994293213\n",
      "Epoch: 5, Batch: 77, Loss: 2.2561933994293213\n",
      "Epoch: 5, Batch: 78, Loss: 2.238722562789917\n",
      "Epoch: 5, Batch: 78, Loss: 2.238722562789917\n",
      "Epoch: 5, Batch: 79, Loss: 2.223479747772217\n",
      "Epoch: 5, Batch: 79, Loss: 2.223479747772217\n",
      "Epoch: 5, Batch: 80, Loss: 2.2069637775421143\n",
      "Epoch: 5, Batch: 80, Loss: 2.2069637775421143\n",
      "Epoch: 5, Batch: 81, Loss: 2.3076038360595703\n",
      "Epoch: 5, Batch: 81, Loss: 2.3076038360595703\n",
      "Epoch: 5, Batch: 82, Loss: 2.267702102661133\n",
      "Epoch: 5, Batch: 82, Loss: 2.267702102661133\n",
      "Epoch: 5, Batch: 83, Loss: 2.2479615211486816\n",
      "Epoch: 5, Batch: 83, Loss: 2.2479615211486816\n",
      "Epoch: 5, Batch: 84, Loss: 2.2380552291870117\n",
      "Epoch: 5, Batch: 84, Loss: 2.2380552291870117\n",
      "Epoch: 5, Batch: 85, Loss: 2.228592872619629\n",
      "Epoch: 5, Batch: 85, Loss: 2.228592872619629\n",
      "Epoch: 5, Batch: 86, Loss: 2.260587692260742\n",
      "Epoch: 5, Batch: 86, Loss: 2.260587692260742\n",
      "Epoch: 5, Batch: 87, Loss: 2.2294435501098633\n",
      "Epoch: 5, Batch: 87, Loss: 2.2294435501098633\n",
      "Epoch: 5, Batch: 88, Loss: 2.2368476390838623\n",
      "Epoch: 5, Batch: 88, Loss: 2.2368476390838623\n",
      "Epoch: 5, Batch: 89, Loss: 2.2348742485046387\n",
      "Epoch: 5, Batch: 89, Loss: 2.2348742485046387\n",
      "Epoch: 5, Batch: 90, Loss: 2.1970252990722656\n",
      "Epoch: 5, Batch: 90, Loss: 2.1970252990722656\n",
      "Epoch: 5, Batch: 91, Loss: 2.196096897125244\n",
      "Epoch: 5, Batch: 91, Loss: 2.196096897125244\n",
      "Epoch: 5, Batch: 92, Loss: 2.1934900283813477\n",
      "Epoch: 5, Batch: 92, Loss: 2.1934900283813477\n",
      "Epoch: 5, Batch: 93, Loss: 2.220266819000244\n",
      "Epoch: 5, Batch: 93, Loss: 2.220266819000244\n",
      "Epoch: 5, Batch: 94, Loss: 2.207430601119995\n",
      "Epoch: 5, Batch: 94, Loss: 2.207430601119995\n",
      "Epoch: 5, Batch: 95, Loss: 2.2072715759277344\n",
      "Epoch: 5, Batch: 95, Loss: 2.2072715759277344\n",
      "Epoch: 5, Batch: 96, Loss: 2.202028274536133\n",
      "Epoch: 5, Batch: 96, Loss: 2.202028274536133\n",
      "Epoch: 5, Batch: 97, Loss: 2.189331531524658\n",
      "Epoch: 5, Batch: 97, Loss: 2.189331531524658\n",
      "Epoch: 5, Batch: 98, Loss: 2.2050180435180664\n",
      "Epoch: 5, Batch: 98, Loss: 2.2050180435180664\n",
      "Epoch: 5, Batch: 99, Loss: 2.179943084716797\n",
      "Epoch: 5, Batch: 99, Loss: 2.179943084716797\n",
      "Generated text: \u0000y plied: to shall dee say.\n",
      "Who she was pritience consh' woult brye;\n",
      "In not spikedle, haven not, and this mamile,\n",
      "The to ho...\n",
      "Generated text: \u0000y plied: to shall dee say.\n",
      "Who she was pritience consh' woult brye;\n",
      "In not spikedle, haven not, and this mamile,\n",
      "The to ho...\n",
      "Epoch: 6, Batch: 0, Loss: 2.204707145690918\n",
      "Epoch: 6, Batch: 0, Loss: 2.204707145690918\n",
      "Epoch: 6, Batch: 1, Loss: 2.2318644523620605\n",
      "Epoch: 6, Batch: 1, Loss: 2.2318644523620605\n",
      "Epoch: 6, Batch: 2, Loss: 2.2281367778778076\n",
      "Epoch: 6, Batch: 2, Loss: 2.2281367778778076\n",
      "Epoch: 6, Batch: 3, Loss: 2.2422590255737305\n",
      "Epoch: 6, Batch: 3, Loss: 2.2422590255737305\n",
      "Epoch: 6, Batch: 4, Loss: 2.183353900909424\n",
      "Epoch: 6, Batch: 4, Loss: 2.183353900909424\n",
      "Epoch: 6, Batch: 5, Loss: 2.2527060508728027\n",
      "Epoch: 6, Batch: 5, Loss: 2.2527060508728027\n",
      "Epoch: 6, Batch: 6, Loss: 2.2122347354888916\n",
      "Epoch: 6, Batch: 6, Loss: 2.2122347354888916\n",
      "Epoch: 6, Batch: 7, Loss: 2.191026210784912\n",
      "Epoch: 6, Batch: 7, Loss: 2.191026210784912\n",
      "Epoch: 6, Batch: 8, Loss: 2.2146167755126953\n",
      "Epoch: 6, Batch: 8, Loss: 2.2146167755126953\n",
      "Epoch: 6, Batch: 9, Loss: 2.1969852447509766\n",
      "Epoch: 6, Batch: 9, Loss: 2.1969852447509766\n",
      "Epoch: 6, Batch: 10, Loss: 2.195556640625\n",
      "Epoch: 6, Batch: 10, Loss: 2.195556640625\n",
      "Epoch: 6, Batch: 11, Loss: 2.2030014991760254\n",
      "Epoch: 6, Batch: 11, Loss: 2.2030014991760254\n",
      "Epoch: 6, Batch: 12, Loss: 2.1562461853027344\n",
      "Epoch: 6, Batch: 12, Loss: 2.1562461853027344\n",
      "Epoch: 6, Batch: 13, Loss: 2.171558380126953\n",
      "Epoch: 6, Batch: 13, Loss: 2.171558380126953\n",
      "Epoch: 6, Batch: 14, Loss: 2.1619131565093994\n",
      "Epoch: 6, Batch: 14, Loss: 2.1619131565093994\n",
      "Epoch: 6, Batch: 15, Loss: 2.2044684886932373\n",
      "Epoch: 6, Batch: 15, Loss: 2.2044684886932373\n",
      "Epoch: 6, Batch: 16, Loss: 2.1885411739349365\n",
      "Epoch: 6, Batch: 16, Loss: 2.1885411739349365\n",
      "Epoch: 6, Batch: 17, Loss: 2.1710660457611084\n",
      "Epoch: 6, Batch: 17, Loss: 2.1710660457611084\n",
      "Epoch: 6, Batch: 18, Loss: 2.1516003608703613\n",
      "Epoch: 6, Batch: 18, Loss: 2.1516003608703613\n",
      "Epoch: 6, Batch: 19, Loss: 2.1711273193359375\n",
      "Epoch: 6, Batch: 19, Loss: 2.1711273193359375\n",
      "Epoch: 6, Batch: 20, Loss: 2.1748971939086914\n",
      "Epoch: 6, Batch: 20, Loss: 2.1748971939086914\n",
      "Epoch: 6, Batch: 21, Loss: 2.1874914169311523\n",
      "Epoch: 6, Batch: 21, Loss: 2.1874914169311523\n",
      "Epoch: 6, Batch: 22, Loss: 2.201296806335449\n",
      "Epoch: 6, Batch: 22, Loss: 2.201296806335449\n",
      "Epoch: 6, Batch: 23, Loss: 2.2022933959960938\n",
      "Epoch: 6, Batch: 23, Loss: 2.2022933959960938\n",
      "Epoch: 6, Batch: 24, Loss: 2.2140350341796875\n",
      "Epoch: 6, Batch: 24, Loss: 2.2140350341796875\n",
      "Epoch: 6, Batch: 25, Loss: 2.1986916065216064\n",
      "Epoch: 6, Batch: 25, Loss: 2.1986916065216064\n",
      "Epoch: 6, Batch: 26, Loss: 2.1805996894836426\n",
      "Epoch: 6, Batch: 26, Loss: 2.1805996894836426\n",
      "Epoch: 6, Batch: 27, Loss: 2.1617679595947266\n",
      "Epoch: 6, Batch: 27, Loss: 2.1617679595947266\n",
      "Epoch: 6, Batch: 28, Loss: 2.1664183139801025\n",
      "Epoch: 6, Batch: 28, Loss: 2.1664183139801025\n",
      "Epoch: 6, Batch: 29, Loss: 2.1888766288757324\n",
      "Epoch: 6, Batch: 29, Loss: 2.1888766288757324\n",
      "Epoch: 6, Batch: 30, Loss: 2.1228890419006348\n",
      "Epoch: 6, Batch: 30, Loss: 2.1228890419006348\n",
      "Epoch: 6, Batch: 31, Loss: 2.149808883666992\n",
      "Epoch: 6, Batch: 31, Loss: 2.149808883666992\n",
      "Epoch: 6, Batch: 32, Loss: 2.134331226348877\n",
      "Epoch: 6, Batch: 32, Loss: 2.134331226348877\n",
      "Epoch: 6, Batch: 33, Loss: 2.1440324783325195\n",
      "Epoch: 6, Batch: 33, Loss: 2.1440324783325195\n",
      "Epoch: 6, Batch: 34, Loss: 2.1729235649108887\n",
      "Epoch: 6, Batch: 34, Loss: 2.1729235649108887\n",
      "Epoch: 6, Batch: 35, Loss: 2.141223192214966\n",
      "Epoch: 6, Batch: 35, Loss: 2.141223192214966\n",
      "Epoch: 6, Batch: 36, Loss: 2.215083599090576\n",
      "Epoch: 6, Batch: 36, Loss: 2.215083599090576\n",
      "Epoch: 6, Batch: 37, Loss: 2.117249011993408\n",
      "Epoch: 6, Batch: 37, Loss: 2.117249011993408\n",
      "Epoch: 6, Batch: 38, Loss: 2.114626407623291\n",
      "Epoch: 6, Batch: 38, Loss: 2.114626407623291\n",
      "Epoch: 6, Batch: 39, Loss: 2.1374504566192627\n",
      "Epoch: 6, Batch: 39, Loss: 2.1374504566192627\n",
      "Epoch: 6, Batch: 40, Loss: 2.107245922088623\n",
      "Epoch: 6, Batch: 40, Loss: 2.107245922088623\n",
      "Epoch: 6, Batch: 41, Loss: 2.1536097526550293\n",
      "Epoch: 6, Batch: 41, Loss: 2.1536097526550293\n",
      "Epoch: 6, Batch: 42, Loss: 2.1353683471679688\n",
      "Epoch: 6, Batch: 42, Loss: 2.1353683471679688\n",
      "Epoch: 6, Batch: 43, Loss: 2.1649608612060547\n",
      "Epoch: 6, Batch: 43, Loss: 2.1649608612060547\n",
      "Epoch: 6, Batch: 44, Loss: 2.157909870147705\n",
      "Epoch: 6, Batch: 44, Loss: 2.157909870147705\n",
      "Epoch: 6, Batch: 45, Loss: 2.198988914489746\n",
      "Epoch: 6, Batch: 45, Loss: 2.198988914489746\n",
      "Epoch: 6, Batch: 46, Loss: 2.1849403381347656\n",
      "Epoch: 6, Batch: 46, Loss: 2.1849403381347656\n",
      "Epoch: 6, Batch: 47, Loss: 2.156787633895874\n",
      "Epoch: 6, Batch: 47, Loss: 2.156787633895874\n",
      "Epoch: 6, Batch: 48, Loss: 2.15205717086792\n",
      "Epoch: 6, Batch: 48, Loss: 2.15205717086792\n",
      "Epoch: 6, Batch: 49, Loss: 2.149580240249634\n",
      "Epoch: 6, Batch: 49, Loss: 2.149580240249634\n",
      "Epoch: 6, Batch: 50, Loss: 2.157182216644287\n",
      "Epoch: 6, Batch: 50, Loss: 2.157182216644287\n",
      "Epoch: 6, Batch: 51, Loss: 2.133655071258545\n",
      "Epoch: 6, Batch: 51, Loss: 2.133655071258545\n",
      "Epoch: 6, Batch: 52, Loss: 2.128450870513916\n",
      "Epoch: 6, Batch: 52, Loss: 2.128450870513916\n",
      "Epoch: 6, Batch: 53, Loss: 2.1264069080352783\n",
      "Epoch: 6, Batch: 53, Loss: 2.1264069080352783\n",
      "Epoch: 6, Batch: 54, Loss: 2.160367012023926\n",
      "Epoch: 6, Batch: 54, Loss: 2.160367012023926\n",
      "Epoch: 6, Batch: 55, Loss: 2.114954948425293\n",
      "Epoch: 6, Batch: 55, Loss: 2.114954948425293\n",
      "Epoch: 6, Batch: 56, Loss: 2.11441707611084\n",
      "Epoch: 6, Batch: 56, Loss: 2.11441707611084\n",
      "Epoch: 6, Batch: 57, Loss: 2.1258373260498047\n",
      "Epoch: 6, Batch: 57, Loss: 2.1258373260498047\n",
      "Epoch: 6, Batch: 58, Loss: 2.103756904602051\n",
      "Epoch: 6, Batch: 58, Loss: 2.103756904602051\n",
      "Epoch: 6, Batch: 59, Loss: 2.1110458374023438\n",
      "Epoch: 6, Batch: 59, Loss: 2.1110458374023438\n",
      "Epoch: 6, Batch: 60, Loss: 2.080777168273926\n",
      "Epoch: 6, Batch: 60, Loss: 2.080777168273926\n",
      "Epoch: 6, Batch: 61, Loss: 2.1533801555633545\n",
      "Epoch: 6, Batch: 61, Loss: 2.1533801555633545\n",
      "Epoch: 6, Batch: 62, Loss: 2.1267330646514893\n",
      "Epoch: 6, Batch: 62, Loss: 2.1267330646514893\n",
      "Epoch: 6, Batch: 63, Loss: 2.0903844833374023\n",
      "Epoch: 6, Batch: 63, Loss: 2.0903844833374023\n",
      "Epoch: 6, Batch: 64, Loss: 2.139509439468384\n",
      "Epoch: 6, Batch: 64, Loss: 2.139509439468384\n",
      "Epoch: 6, Batch: 65, Loss: 2.1262965202331543\n",
      "Epoch: 6, Batch: 65, Loss: 2.1262965202331543\n",
      "Epoch: 6, Batch: 66, Loss: 2.1359543800354004\n",
      "Epoch: 6, Batch: 66, Loss: 2.1359543800354004\n",
      "Epoch: 6, Batch: 67, Loss: 2.1327712535858154\n",
      "Epoch: 6, Batch: 67, Loss: 2.1327712535858154\n",
      "Epoch: 6, Batch: 68, Loss: 2.1361489295959473\n",
      "Epoch: 6, Batch: 68, Loss: 2.1361489295959473\n",
      "Epoch: 6, Batch: 69, Loss: 2.137971878051758\n",
      "Epoch: 6, Batch: 69, Loss: 2.137971878051758\n",
      "Epoch: 6, Batch: 70, Loss: 2.113162040710449\n",
      "Epoch: 6, Batch: 70, Loss: 2.113162040710449\n",
      "Epoch: 6, Batch: 71, Loss: 2.060162305831909\n",
      "Epoch: 6, Batch: 71, Loss: 2.060162305831909\n",
      "Epoch: 6, Batch: 72, Loss: 2.1014821529388428\n",
      "Epoch: 6, Batch: 72, Loss: 2.1014821529388428\n",
      "Epoch: 6, Batch: 73, Loss: 2.0998432636260986\n",
      "Epoch: 6, Batch: 73, Loss: 2.0998432636260986\n",
      "Epoch: 6, Batch: 74, Loss: 2.0697338581085205\n",
      "Epoch: 6, Batch: 74, Loss: 2.0697338581085205\n",
      "Epoch: 6, Batch: 75, Loss: 2.060631275177002\n",
      "Epoch: 6, Batch: 75, Loss: 2.060631275177002\n",
      "Epoch: 6, Batch: 76, Loss: 2.07428240776062\n",
      "Epoch: 6, Batch: 76, Loss: 2.07428240776062\n",
      "Epoch: 6, Batch: 77, Loss: 2.075778007507324\n",
      "Epoch: 6, Batch: 77, Loss: 2.075778007507324\n",
      "Epoch: 6, Batch: 78, Loss: 2.0844221115112305\n",
      "Epoch: 6, Batch: 78, Loss: 2.0844221115112305\n",
      "Epoch: 6, Batch: 79, Loss: 2.101378917694092\n",
      "Epoch: 6, Batch: 79, Loss: 2.101378917694092\n",
      "Epoch: 6, Batch: 80, Loss: 2.0714995861053467\n",
      "Epoch: 6, Batch: 80, Loss: 2.0714995861053467\n",
      "Epoch: 6, Batch: 81, Loss: 2.0808191299438477\n",
      "Epoch: 6, Batch: 81, Loss: 2.0808191299438477\n",
      "Epoch: 6, Batch: 82, Loss: 2.133978843688965\n",
      "Epoch: 6, Batch: 82, Loss: 2.133978843688965\n",
      "Epoch: 6, Batch: 83, Loss: 2.101480484008789\n",
      "Epoch: 6, Batch: 83, Loss: 2.101480484008789\n",
      "Epoch: 6, Batch: 84, Loss: 2.1226587295532227\n",
      "Epoch: 6, Batch: 84, Loss: 2.1226587295532227\n",
      "Epoch: 6, Batch: 85, Loss: 2.0546860694885254\n",
      "Epoch: 6, Batch: 85, Loss: 2.0546860694885254\n",
      "Epoch: 6, Batch: 86, Loss: 2.1380534172058105\n",
      "Epoch: 6, Batch: 86, Loss: 2.1380534172058105\n",
      "Epoch: 6, Batch: 87, Loss: 2.1343178749084473\n",
      "Epoch: 6, Batch: 87, Loss: 2.1343178749084473\n",
      "Epoch: 6, Batch: 88, Loss: 2.0940632820129395\n",
      "Epoch: 6, Batch: 88, Loss: 2.0940632820129395\n",
      "Epoch: 6, Batch: 89, Loss: 2.104340076446533\n",
      "Epoch: 6, Batch: 89, Loss: 2.104340076446533\n",
      "Epoch: 6, Batch: 90, Loss: 2.110887050628662\n",
      "Epoch: 6, Batch: 90, Loss: 2.110887050628662\n",
      "Epoch: 6, Batch: 91, Loss: 2.059473991394043\n",
      "Epoch: 6, Batch: 91, Loss: 2.059473991394043\n",
      "Epoch: 6, Batch: 92, Loss: 2.077322244644165\n",
      "Epoch: 6, Batch: 92, Loss: 2.077322244644165\n",
      "Epoch: 6, Batch: 93, Loss: 2.0586905479431152\n",
      "Epoch: 6, Batch: 93, Loss: 2.0586905479431152\n",
      "Epoch: 6, Batch: 94, Loss: 2.114793300628662\n",
      "Epoch: 6, Batch: 94, Loss: 2.114793300628662\n",
      "Epoch: 6, Batch: 95, Loss: 2.068190574645996\n",
      "Epoch: 6, Batch: 95, Loss: 2.068190574645996\n",
      "Epoch: 6, Batch: 96, Loss: 2.032574415206909\n",
      "Epoch: 6, Batch: 96, Loss: 2.032574415206909\n",
      "Epoch: 6, Batch: 97, Loss: 2.056199073791504\n",
      "Epoch: 6, Batch: 97, Loss: 2.056199073791504\n",
      "Epoch: 6, Batch: 98, Loss: 2.0714848041534424\n",
      "Epoch: 6, Batch: 98, Loss: 2.0714848041534424\n",
      "Epoch: 6, Batch: 99, Loss: 2.058877944946289\n",
      "Epoch: 6, Batch: 99, Loss: 2.058877944946289\n",
      "Generated text: \u0000havo's;\n",
      "Reth the should Have didged none,\n",
      "If hope a poor tell hand, wrip their forme,\n",
      "Who loudling bease caure it befet.\n",
      "\n",
      "CR...\n",
      "Generated text: \u0000havo's;\n",
      "Reth the should Have didged none,\n",
      "If hope a poor tell hand, wrip their forme,\n",
      "Who loudling bease caure it befet.\n",
      "\n",
      "CR...\n",
      "Epoch: 7, Batch: 0, Loss: 2.0563182830810547\n",
      "Epoch: 7, Batch: 0, Loss: 2.0563182830810547\n",
      "Epoch: 7, Batch: 1, Loss: 2.1004910469055176\n",
      "Epoch: 7, Batch: 1, Loss: 2.1004910469055176\n",
      "Epoch: 7, Batch: 2, Loss: 2.110088348388672\n",
      "Epoch: 7, Batch: 2, Loss: 2.110088348388672\n",
      "Epoch: 7, Batch: 3, Loss: 2.0345094203948975\n",
      "Epoch: 7, Batch: 3, Loss: 2.0345094203948975\n",
      "Epoch: 7, Batch: 4, Loss: 2.089939594268799\n",
      "Epoch: 7, Batch: 4, Loss: 2.089939594268799\n",
      "Epoch: 7, Batch: 5, Loss: 2.058985948562622\n",
      "Epoch: 7, Batch: 5, Loss: 2.058985948562622\n",
      "Epoch: 7, Batch: 6, Loss: 2.122910976409912\n",
      "Epoch: 7, Batch: 6, Loss: 2.122910976409912\n",
      "Epoch: 7, Batch: 7, Loss: 2.055642604827881\n",
      "Epoch: 7, Batch: 7, Loss: 2.055642604827881\n",
      "Epoch: 7, Batch: 8, Loss: 2.093977451324463\n",
      "Epoch: 7, Batch: 8, Loss: 2.093977451324463\n",
      "Epoch: 7, Batch: 9, Loss: 2.0546414852142334\n",
      "Epoch: 7, Batch: 9, Loss: 2.0546414852142334\n",
      "Epoch: 7, Batch: 10, Loss: 2.0890026092529297\n",
      "Epoch: 7, Batch: 10, Loss: 2.0890026092529297\n",
      "Epoch: 7, Batch: 11, Loss: 2.0621042251586914\n",
      "Epoch: 7, Batch: 11, Loss: 2.0621042251586914\n",
      "Epoch: 7, Batch: 12, Loss: 2.0252461433410645\n",
      "Epoch: 7, Batch: 12, Loss: 2.0252461433410645\n",
      "Epoch: 7, Batch: 13, Loss: 2.0707569122314453\n",
      "Epoch: 7, Batch: 13, Loss: 2.0707569122314453\n",
      "Epoch: 7, Batch: 14, Loss: 2.0338399410247803\n",
      "Epoch: 7, Batch: 14, Loss: 2.0338399410247803\n",
      "Epoch: 7, Batch: 15, Loss: 2.040252208709717\n",
      "Epoch: 7, Batch: 15, Loss: 2.040252208709717\n",
      "Epoch: 7, Batch: 16, Loss: 2.1012802124023438\n",
      "Epoch: 7, Batch: 16, Loss: 2.1012802124023438\n",
      "Epoch: 7, Batch: 17, Loss: 2.0106730461120605\n",
      "Epoch: 7, Batch: 17, Loss: 2.0106730461120605\n",
      "Epoch: 7, Batch: 18, Loss: 2.043452501296997\n",
      "Epoch: 7, Batch: 18, Loss: 2.043452501296997\n",
      "Epoch: 7, Batch: 19, Loss: 2.048158645629883\n",
      "Epoch: 7, Batch: 19, Loss: 2.048158645629883\n",
      "Epoch: 7, Batch: 20, Loss: 2.0741801261901855\n",
      "Epoch: 7, Batch: 20, Loss: 2.0741801261901855\n",
      "Epoch: 7, Batch: 21, Loss: 2.090500831604004\n",
      "Epoch: 7, Batch: 21, Loss: 2.090500831604004\n",
      "Epoch: 7, Batch: 22, Loss: 2.117097854614258\n",
      "Epoch: 7, Batch: 22, Loss: 2.117097854614258\n",
      "Epoch: 7, Batch: 23, Loss: 2.0693557262420654\n",
      "Epoch: 7, Batch: 23, Loss: 2.0693557262420654\n",
      "Epoch: 7, Batch: 24, Loss: 2.0710318088531494\n",
      "Epoch: 7, Batch: 24, Loss: 2.0710318088531494\n",
      "Epoch: 7, Batch: 25, Loss: 2.087092876434326\n",
      "Epoch: 7, Batch: 25, Loss: 2.087092876434326\n",
      "Epoch: 7, Batch: 26, Loss: 2.0376765727996826\n",
      "Epoch: 7, Batch: 26, Loss: 2.0376765727996826\n",
      "Epoch: 7, Batch: 27, Loss: 2.0297293663024902\n",
      "Epoch: 7, Batch: 27, Loss: 2.0297293663024902\n",
      "Epoch: 7, Batch: 28, Loss: 2.032176971435547\n",
      "Epoch: 7, Batch: 28, Loss: 2.032176971435547\n",
      "Epoch: 7, Batch: 29, Loss: 2.0194225311279297\n",
      "Epoch: 7, Batch: 29, Loss: 2.0194225311279297\n",
      "Epoch: 7, Batch: 30, Loss: 2.0123634338378906\n",
      "Epoch: 7, Batch: 30, Loss: 2.0123634338378906\n",
      "Epoch: 7, Batch: 31, Loss: 2.0131373405456543\n",
      "Epoch: 7, Batch: 31, Loss: 2.0131373405456543\n",
      "Epoch: 7, Batch: 32, Loss: 2.007093667984009\n",
      "Epoch: 7, Batch: 32, Loss: 2.007093667984009\n",
      "Epoch: 7, Batch: 33, Loss: 2.03743839263916\n",
      "Epoch: 7, Batch: 33, Loss: 2.03743839263916\n",
      "Epoch: 7, Batch: 34, Loss: 2.010953903198242\n",
      "Epoch: 7, Batch: 34, Loss: 2.010953903198242\n",
      "Epoch: 7, Batch: 35, Loss: 2.008622407913208\n",
      "Epoch: 7, Batch: 35, Loss: 2.008622407913208\n",
      "Epoch: 7, Batch: 36, Loss: 2.0254435539245605\n",
      "Epoch: 7, Batch: 36, Loss: 2.0254435539245605\n",
      "Epoch: 7, Batch: 37, Loss: 2.0120139122009277\n",
      "Epoch: 7, Batch: 37, Loss: 2.0120139122009277\n",
      "Epoch: 7, Batch: 38, Loss: 2.0345728397369385\n",
      "Epoch: 7, Batch: 38, Loss: 2.0345728397369385\n",
      "Epoch: 7, Batch: 39, Loss: 1.9910907745361328\n",
      "Epoch: 7, Batch: 39, Loss: 1.9910907745361328\n",
      "Epoch: 7, Batch: 40, Loss: 1.9934136867523193\n",
      "Epoch: 7, Batch: 40, Loss: 1.9934136867523193\n",
      "Epoch: 7, Batch: 41, Loss: 2.052860736846924\n",
      "Epoch: 7, Batch: 41, Loss: 2.052860736846924\n",
      "Epoch: 7, Batch: 42, Loss: 2.059678792953491\n",
      "Epoch: 7, Batch: 42, Loss: 2.059678792953491\n",
      "Epoch: 7, Batch: 43, Loss: 2.0348105430603027\n",
      "Epoch: 7, Batch: 43, Loss: 2.0348105430603027\n",
      "Epoch: 7, Batch: 44, Loss: 2.0579214096069336\n",
      "Epoch: 7, Batch: 44, Loss: 2.0579214096069336\n",
      "Epoch: 7, Batch: 45, Loss: 2.0404181480407715\n",
      "Epoch: 7, Batch: 45, Loss: 2.0404181480407715\n",
      "Epoch: 7, Batch: 46, Loss: 2.064255952835083\n",
      "Epoch: 7, Batch: 46, Loss: 2.064255952835083\n",
      "Epoch: 7, Batch: 47, Loss: 2.0363826751708984\n",
      "Epoch: 7, Batch: 47, Loss: 2.0363826751708984\n",
      "Epoch: 7, Batch: 48, Loss: 2.0095508098602295\n",
      "Epoch: 7, Batch: 48, Loss: 2.0095508098602295\n",
      "Epoch: 7, Batch: 49, Loss: 2.0048131942749023\n",
      "Epoch: 7, Batch: 49, Loss: 2.0048131942749023\n",
      "Epoch: 7, Batch: 50, Loss: 2.0797407627105713\n",
      "Epoch: 7, Batch: 50, Loss: 2.0797407627105713\n",
      "Epoch: 7, Batch: 51, Loss: 2.044386386871338\n",
      "Epoch: 7, Batch: 51, Loss: 2.044386386871338\n",
      "Epoch: 7, Batch: 52, Loss: 2.023489236831665\n",
      "Epoch: 7, Batch: 52, Loss: 2.023489236831665\n",
      "Epoch: 7, Batch: 53, Loss: 2.012300968170166\n",
      "Epoch: 7, Batch: 53, Loss: 2.012300968170166\n",
      "Epoch: 7, Batch: 54, Loss: 2.019063949584961\n",
      "Epoch: 7, Batch: 54, Loss: 2.019063949584961\n",
      "Epoch: 7, Batch: 55, Loss: 1.9917161464691162\n",
      "Epoch: 7, Batch: 55, Loss: 1.9917161464691162\n",
      "Epoch: 7, Batch: 56, Loss: 2.019052028656006\n",
      "Epoch: 7, Batch: 56, Loss: 2.019052028656006\n",
      "Epoch: 7, Batch: 57, Loss: 1.9746663570404053\n",
      "Epoch: 7, Batch: 57, Loss: 1.9746663570404053\n",
      "Epoch: 7, Batch: 58, Loss: 1.9755197763442993\n",
      "Epoch: 7, Batch: 58, Loss: 1.9755197763442993\n",
      "Epoch: 7, Batch: 59, Loss: 1.9965726137161255\n",
      "Epoch: 7, Batch: 59, Loss: 1.9965726137161255\n",
      "Epoch: 7, Batch: 60, Loss: 2.0072271823883057\n",
      "Epoch: 7, Batch: 60, Loss: 2.0072271823883057\n",
      "Epoch: 7, Batch: 61, Loss: 2.0279228687286377\n",
      "Epoch: 7, Batch: 61, Loss: 2.0279228687286377\n",
      "Epoch: 7, Batch: 62, Loss: 2.0131232738494873\n",
      "Epoch: 7, Batch: 62, Loss: 2.0131232738494873\n",
      "Epoch: 7, Batch: 63, Loss: 2.033074140548706\n",
      "Epoch: 7, Batch: 63, Loss: 2.033074140548706\n",
      "Epoch: 7, Batch: 64, Loss: 2.073094367980957\n",
      "Epoch: 7, Batch: 64, Loss: 2.073094367980957\n",
      "Epoch: 7, Batch: 65, Loss: 1.9852652549743652\n",
      "Epoch: 7, Batch: 65, Loss: 1.9852652549743652\n",
      "Epoch: 7, Batch: 66, Loss: 2.012144088745117\n",
      "Epoch: 7, Batch: 66, Loss: 2.012144088745117\n",
      "Epoch: 7, Batch: 67, Loss: 2.0362472534179688\n",
      "Epoch: 7, Batch: 67, Loss: 2.0362472534179688\n",
      "Epoch: 7, Batch: 68, Loss: 2.003793239593506\n",
      "Epoch: 7, Batch: 68, Loss: 2.003793239593506\n",
      "Epoch: 7, Batch: 69, Loss: 1.9992774724960327\n",
      "Epoch: 7, Batch: 69, Loss: 1.9992774724960327\n",
      "Epoch: 7, Batch: 70, Loss: 1.9672549962997437\n",
      "Epoch: 7, Batch: 70, Loss: 1.9672549962997437\n",
      "Epoch: 7, Batch: 71, Loss: 2.0516462326049805\n",
      "Epoch: 7, Batch: 71, Loss: 2.0516462326049805\n",
      "Epoch: 7, Batch: 72, Loss: 1.9843008518218994\n",
      "Epoch: 7, Batch: 72, Loss: 1.9843008518218994\n",
      "Epoch: 7, Batch: 73, Loss: 1.9849157333374023\n",
      "Epoch: 7, Batch: 73, Loss: 1.9849157333374023\n",
      "Epoch: 7, Batch: 74, Loss: 1.946134328842163\n",
      "Epoch: 7, Batch: 74, Loss: 1.946134328842163\n",
      "Epoch: 7, Batch: 75, Loss: 2.017606735229492\n",
      "Epoch: 7, Batch: 75, Loss: 2.017606735229492\n",
      "Epoch: 7, Batch: 76, Loss: 1.9966930150985718\n",
      "Epoch: 7, Batch: 76, Loss: 1.9966930150985718\n",
      "Epoch: 7, Batch: 77, Loss: 1.9762458801269531\n",
      "Epoch: 7, Batch: 77, Loss: 1.9762458801269531\n",
      "Epoch: 7, Batch: 78, Loss: 2.0111567974090576\n",
      "Epoch: 7, Batch: 78, Loss: 2.0111567974090576\n",
      "Epoch: 7, Batch: 79, Loss: 1.9742990732192993\n",
      "Epoch: 7, Batch: 79, Loss: 1.9742990732192993\n",
      "Epoch: 7, Batch: 80, Loss: 1.9770517349243164\n",
      "Epoch: 7, Batch: 80, Loss: 1.9770517349243164\n",
      "Epoch: 7, Batch: 81, Loss: 1.9625976085662842\n",
      "Epoch: 7, Batch: 81, Loss: 1.9625976085662842\n",
      "Epoch: 7, Batch: 82, Loss: 2.0216259956359863\n",
      "Epoch: 7, Batch: 82, Loss: 2.0216259956359863\n",
      "Epoch: 7, Batch: 83, Loss: 2.0401196479797363\n",
      "Epoch: 7, Batch: 83, Loss: 2.0401196479797363\n",
      "Epoch: 7, Batch: 84, Loss: 2.0196166038513184\n",
      "Epoch: 7, Batch: 84, Loss: 2.0196166038513184\n",
      "Epoch: 7, Batch: 85, Loss: 2.007500171661377\n",
      "Epoch: 7, Batch: 85, Loss: 2.007500171661377\n",
      "Epoch: 7, Batch: 86, Loss: 1.9596842527389526\n",
      "Epoch: 7, Batch: 86, Loss: 1.9596842527389526\n",
      "Epoch: 7, Batch: 87, Loss: 1.9816945791244507\n",
      "Epoch: 7, Batch: 87, Loss: 1.9816945791244507\n",
      "Epoch: 7, Batch: 88, Loss: 1.9789090156555176\n",
      "Epoch: 7, Batch: 88, Loss: 1.9789090156555176\n",
      "Epoch: 7, Batch: 89, Loss: 1.943758249282837\n",
      "Epoch: 7, Batch: 89, Loss: 1.943758249282837\n",
      "Epoch: 7, Batch: 90, Loss: 1.9871773719787598\n",
      "Epoch: 7, Batch: 90, Loss: 1.9871773719787598\n",
      "Epoch: 7, Batch: 91, Loss: 1.9724137783050537\n",
      "Epoch: 7, Batch: 91, Loss: 1.9724137783050537\n",
      "Epoch: 7, Batch: 92, Loss: 1.943604826927185\n",
      "Epoch: 7, Batch: 92, Loss: 1.943604826927185\n",
      "Epoch: 7, Batch: 93, Loss: 1.9786673784255981\n",
      "Epoch: 7, Batch: 93, Loss: 1.9786673784255981\n",
      "Epoch: 7, Batch: 94, Loss: 1.9731392860412598\n",
      "Epoch: 7, Batch: 94, Loss: 1.9731392860412598\n",
      "Epoch: 7, Batch: 95, Loss: 1.9592750072479248\n",
      "Epoch: 7, Batch: 95, Loss: 1.9592750072479248\n",
      "Epoch: 7, Batch: 96, Loss: 1.976479172706604\n",
      "Epoch: 7, Batch: 96, Loss: 1.976479172706604\n",
      "Epoch: 7, Batch: 97, Loss: 1.980762004852295\n",
      "Epoch: 7, Batch: 97, Loss: 1.980762004852295\n",
      "Epoch: 7, Batch: 98, Loss: 1.989741325378418\n",
      "Epoch: 7, Batch: 98, Loss: 1.989741325378418\n",
      "Epoch: 7, Batch: 99, Loss: 2.0069222450256348\n",
      "Epoch: 7, Batch: 99, Loss: 2.0069222450256348\n",
      "Generated text: \u0000ANUS:\n",
      "O sproke Rustand saisarn, forelom us:\n",
      "I were a cuttions ye: you shall beary.\n",
      "Od, putiand, that feeither my warmy.\n",
      "\n",
      "BRUT...\n",
      "Generated text: \u0000ANUS:\n",
      "O sproke Rustand saisarn, forelom us:\n",
      "I were a cuttions ye: you shall beary.\n",
      "Od, putiand, that feeither my warmy.\n",
      "\n",
      "BRUT...\n",
      "Epoch: 8, Batch: 0, Loss: 1.9975957870483398\n",
      "Epoch: 8, Batch: 0, Loss: 1.9975957870483398\n",
      "Epoch: 8, Batch: 1, Loss: 1.970907211303711\n",
      "Epoch: 8, Batch: 1, Loss: 1.970907211303711\n",
      "Epoch: 8, Batch: 2, Loss: 1.9829370975494385\n",
      "Epoch: 8, Batch: 2, Loss: 1.9829370975494385\n",
      "Epoch: 8, Batch: 3, Loss: 1.9595650434494019\n",
      "Epoch: 8, Batch: 3, Loss: 1.9595650434494019\n",
      "Epoch: 8, Batch: 4, Loss: 2.012636661529541\n",
      "Epoch: 8, Batch: 4, Loss: 2.012636661529541\n",
      "Epoch: 8, Batch: 5, Loss: 2.0140178203582764\n",
      "Epoch: 8, Batch: 5, Loss: 2.0140178203582764\n",
      "Epoch: 8, Batch: 6, Loss: 2.0100672245025635\n",
      "Epoch: 8, Batch: 6, Loss: 2.0100672245025635\n",
      "Epoch: 8, Batch: 7, Loss: 1.9946210384368896\n",
      "Epoch: 8, Batch: 7, Loss: 1.9946210384368896\n",
      "Epoch: 8, Batch: 8, Loss: 1.9459636211395264\n",
      "Epoch: 8, Batch: 8, Loss: 1.9459636211395264\n",
      "Epoch: 8, Batch: 9, Loss: 1.946866512298584\n",
      "Epoch: 8, Batch: 9, Loss: 1.946866512298584\n",
      "Epoch: 8, Batch: 10, Loss: 1.9743015766143799\n",
      "Epoch: 8, Batch: 10, Loss: 1.9743015766143799\n",
      "Epoch: 8, Batch: 11, Loss: 1.9691054821014404\n",
      "Epoch: 8, Batch: 11, Loss: 1.9691054821014404\n",
      "Epoch: 8, Batch: 12, Loss: 1.9777333736419678\n",
      "Epoch: 8, Batch: 12, Loss: 1.9777333736419678\n",
      "Epoch: 8, Batch: 13, Loss: 1.9545185565948486\n",
      "Epoch: 8, Batch: 13, Loss: 1.9545185565948486\n",
      "Epoch: 8, Batch: 14, Loss: 1.9544354677200317\n",
      "Epoch: 8, Batch: 14, Loss: 1.9544354677200317\n",
      "Epoch: 8, Batch: 15, Loss: 1.9923139810562134\n",
      "Epoch: 8, Batch: 15, Loss: 1.9923139810562134\n",
      "Epoch: 8, Batch: 16, Loss: 1.9645497798919678\n",
      "Epoch: 8, Batch: 16, Loss: 1.9645497798919678\n",
      "Epoch: 8, Batch: 17, Loss: 1.9160391092300415\n",
      "Epoch: 8, Batch: 17, Loss: 1.9160391092300415\n",
      "Epoch: 8, Batch: 18, Loss: 1.8932673931121826\n",
      "Epoch: 8, Batch: 18, Loss: 1.8932673931121826\n",
      "Epoch: 8, Batch: 19, Loss: 1.9532482624053955\n",
      "Epoch: 8, Batch: 19, Loss: 1.9532482624053955\n",
      "Epoch: 8, Batch: 20, Loss: 1.918674349784851\n",
      "Epoch: 8, Batch: 20, Loss: 1.918674349784851\n",
      "Epoch: 8, Batch: 21, Loss: 1.9259759187698364\n",
      "Epoch: 8, Batch: 21, Loss: 1.9259759187698364\n",
      "Epoch: 8, Batch: 22, Loss: 1.9970364570617676\n",
      "Epoch: 8, Batch: 22, Loss: 1.9970364570617676\n",
      "Epoch: 8, Batch: 23, Loss: 1.9713873863220215\n",
      "Epoch: 8, Batch: 23, Loss: 1.9713873863220215\n",
      "Epoch: 8, Batch: 24, Loss: 1.9848756790161133\n",
      "Epoch: 8, Batch: 24, Loss: 1.9848756790161133\n",
      "Epoch: 8, Batch: 25, Loss: 1.9576654434204102\n",
      "Epoch: 8, Batch: 25, Loss: 1.9576654434204102\n",
      "Epoch: 8, Batch: 26, Loss: 1.9754292964935303\n",
      "Epoch: 8, Batch: 26, Loss: 1.9754292964935303\n",
      "Epoch: 8, Batch: 27, Loss: 2.0093016624450684\n",
      "Epoch: 8, Batch: 27, Loss: 2.0093016624450684\n",
      "Epoch: 8, Batch: 28, Loss: 2.013759136199951\n",
      "Epoch: 8, Batch: 28, Loss: 2.013759136199951\n",
      "Epoch: 8, Batch: 29, Loss: 1.986190676689148\n",
      "Epoch: 8, Batch: 29, Loss: 1.986190676689148\n",
      "Epoch: 8, Batch: 30, Loss: 1.957010269165039\n",
      "Epoch: 8, Batch: 30, Loss: 1.957010269165039\n",
      "Epoch: 8, Batch: 31, Loss: 1.9624898433685303\n",
      "Epoch: 8, Batch: 31, Loss: 1.9624898433685303\n",
      "Epoch: 8, Batch: 32, Loss: 1.9121410846710205\n",
      "Epoch: 8, Batch: 32, Loss: 1.9121410846710205\n",
      "Epoch: 8, Batch: 33, Loss: 1.9316598176956177\n",
      "Epoch: 8, Batch: 33, Loss: 1.9316598176956177\n",
      "Epoch: 8, Batch: 34, Loss: 1.892889380455017\n",
      "Epoch: 8, Batch: 34, Loss: 1.892889380455017\n",
      "Epoch: 8, Batch: 35, Loss: 1.8623478412628174\n",
      "Epoch: 8, Batch: 35, Loss: 1.8623478412628174\n",
      "Epoch: 8, Batch: 36, Loss: 1.9006593227386475\n",
      "Epoch: 8, Batch: 36, Loss: 1.9006593227386475\n",
      "Epoch: 8, Batch: 37, Loss: 1.9425969123840332\n",
      "Epoch: 8, Batch: 37, Loss: 1.9425969123840332\n",
      "Epoch: 8, Batch: 38, Loss: 1.9184170961380005\n",
      "Epoch: 8, Batch: 38, Loss: 1.9184170961380005\n",
      "Epoch: 8, Batch: 39, Loss: 1.914684772491455\n",
      "Epoch: 8, Batch: 39, Loss: 1.914684772491455\n",
      "Epoch: 8, Batch: 40, Loss: 1.8881335258483887\n",
      "Epoch: 8, Batch: 40, Loss: 1.8881335258483887\n",
      "Epoch: 8, Batch: 41, Loss: 1.9624340534210205\n",
      "Epoch: 8, Batch: 41, Loss: 1.9624340534210205\n",
      "Epoch: 8, Batch: 42, Loss: 1.9475840330123901\n",
      "Epoch: 8, Batch: 42, Loss: 1.9475840330123901\n",
      "Epoch: 8, Batch: 43, Loss: 1.9996657371520996\n",
      "Epoch: 8, Batch: 43, Loss: 1.9996657371520996\n",
      "Epoch: 8, Batch: 44, Loss: 1.9786412715911865\n",
      "Epoch: 8, Batch: 44, Loss: 1.9786412715911865\n",
      "Epoch: 8, Batch: 45, Loss: 1.9140682220458984\n",
      "Epoch: 8, Batch: 45, Loss: 1.9140682220458984\n",
      "Epoch: 8, Batch: 46, Loss: 1.9586303234100342\n",
      "Epoch: 8, Batch: 46, Loss: 1.9586303234100342\n",
      "Epoch: 8, Batch: 47, Loss: 1.9511380195617676\n",
      "Epoch: 8, Batch: 47, Loss: 1.9511380195617676\n",
      "Epoch: 8, Batch: 48, Loss: 1.9261813163757324\n",
      "Epoch: 8, Batch: 48, Loss: 1.9261813163757324\n",
      "Epoch: 8, Batch: 49, Loss: 1.9262292385101318\n",
      "Epoch: 8, Batch: 49, Loss: 1.9262292385101318\n",
      "Epoch: 8, Batch: 50, Loss: 1.9264304637908936\n",
      "Epoch: 8, Batch: 50, Loss: 1.9264304637908936\n",
      "Epoch: 8, Batch: 51, Loss: 1.9239407777786255\n",
      "Epoch: 8, Batch: 51, Loss: 1.9239407777786255\n",
      "Epoch: 8, Batch: 52, Loss: 1.9732770919799805\n",
      "Epoch: 8, Batch: 52, Loss: 1.9732770919799805\n",
      "Epoch: 8, Batch: 53, Loss: 1.9872684478759766\n",
      "Epoch: 8, Batch: 53, Loss: 1.9872684478759766\n",
      "Epoch: 8, Batch: 54, Loss: 1.9191479682922363\n",
      "Epoch: 8, Batch: 54, Loss: 1.9191479682922363\n",
      "Epoch: 8, Batch: 55, Loss: 1.9266963005065918\n",
      "Epoch: 8, Batch: 55, Loss: 1.9266963005065918\n",
      "Epoch: 8, Batch: 56, Loss: 1.9053831100463867\n",
      "Epoch: 8, Batch: 56, Loss: 1.9053831100463867\n",
      "Epoch: 8, Batch: 57, Loss: 1.9734137058258057\n",
      "Epoch: 8, Batch: 57, Loss: 1.9734137058258057\n",
      "Epoch: 8, Batch: 58, Loss: 1.9241210222244263\n",
      "Epoch: 8, Batch: 58, Loss: 1.9241210222244263\n",
      "Epoch: 8, Batch: 59, Loss: 1.9211146831512451\n",
      "Epoch: 8, Batch: 59, Loss: 1.9211146831512451\n",
      "Epoch: 8, Batch: 60, Loss: 1.9224200248718262\n",
      "Epoch: 8, Batch: 60, Loss: 1.9224200248718262\n",
      "Epoch: 8, Batch: 61, Loss: 1.956627368927002\n",
      "Epoch: 8, Batch: 61, Loss: 1.956627368927002\n",
      "Epoch: 8, Batch: 62, Loss: 1.9826269149780273\n",
      "Epoch: 8, Batch: 62, Loss: 1.9826269149780273\n",
      "Epoch: 8, Batch: 63, Loss: 1.9447654485702515\n",
      "Epoch: 8, Batch: 63, Loss: 1.9447654485702515\n",
      "Epoch: 8, Batch: 64, Loss: 1.9171197414398193\n",
      "Epoch: 8, Batch: 64, Loss: 1.9171197414398193\n",
      "Epoch: 8, Batch: 65, Loss: 1.9862308502197266\n",
      "Epoch: 8, Batch: 65, Loss: 1.9862308502197266\n",
      "Epoch: 8, Batch: 66, Loss: 1.9775559902191162\n",
      "Epoch: 8, Batch: 66, Loss: 1.9775559902191162\n",
      "Epoch: 8, Batch: 67, Loss: 1.898674726486206\n",
      "Epoch: 8, Batch: 67, Loss: 1.898674726486206\n",
      "Epoch: 8, Batch: 68, Loss: 1.9527795314788818\n",
      "Epoch: 8, Batch: 68, Loss: 1.9527795314788818\n",
      "Epoch: 8, Batch: 69, Loss: 1.9170223474502563\n",
      "Epoch: 8, Batch: 69, Loss: 1.9170223474502563\n",
      "Epoch: 8, Batch: 70, Loss: 1.9275116920471191\n",
      "Epoch: 8, Batch: 70, Loss: 1.9275116920471191\n",
      "Epoch: 8, Batch: 71, Loss: 1.9113805294036865\n",
      "Epoch: 8, Batch: 71, Loss: 1.9113805294036865\n",
      "Epoch: 8, Batch: 72, Loss: 1.899764060974121\n",
      "Epoch: 8, Batch: 72, Loss: 1.899764060974121\n",
      "Epoch: 8, Batch: 73, Loss: 1.8955481052398682\n",
      "Epoch: 8, Batch: 73, Loss: 1.8955481052398682\n",
      "Epoch: 8, Batch: 74, Loss: 1.929243564605713\n",
      "Epoch: 8, Batch: 74, Loss: 1.929243564605713\n",
      "Epoch: 8, Batch: 75, Loss: 1.89359712600708\n",
      "Epoch: 8, Batch: 75, Loss: 1.89359712600708\n",
      "Epoch: 8, Batch: 76, Loss: 1.8795294761657715\n",
      "Epoch: 8, Batch: 76, Loss: 1.8795294761657715\n",
      "Epoch: 8, Batch: 77, Loss: 1.8639616966247559\n",
      "Epoch: 8, Batch: 77, Loss: 1.8639616966247559\n",
      "Epoch: 8, Batch: 78, Loss: 1.8705103397369385\n",
      "Epoch: 8, Batch: 78, Loss: 1.8705103397369385\n",
      "Epoch: 8, Batch: 79, Loss: 1.871935486793518\n",
      "Epoch: 8, Batch: 79, Loss: 1.871935486793518\n",
      "Epoch: 8, Batch: 80, Loss: 1.8665454387664795\n",
      "Epoch: 8, Batch: 80, Loss: 1.8665454387664795\n",
      "Epoch: 8, Batch: 81, Loss: 1.9358818531036377\n",
      "Epoch: 8, Batch: 81, Loss: 1.9358818531036377\n",
      "Epoch: 8, Batch: 82, Loss: 1.9410943984985352\n",
      "Epoch: 8, Batch: 82, Loss: 1.9410943984985352\n",
      "Epoch: 8, Batch: 83, Loss: 1.9180753231048584\n",
      "Epoch: 8, Batch: 83, Loss: 1.9180753231048584\n",
      "Epoch: 8, Batch: 84, Loss: 1.938232421875\n",
      "Epoch: 8, Batch: 84, Loss: 1.938232421875\n",
      "Epoch: 8, Batch: 85, Loss: 1.9232854843139648\n",
      "Epoch: 8, Batch: 85, Loss: 1.9232854843139648\n",
      "Epoch: 8, Batch: 86, Loss: 1.8713117837905884\n",
      "Epoch: 8, Batch: 86, Loss: 1.8713117837905884\n",
      "Epoch: 8, Batch: 87, Loss: 1.9311450719833374\n",
      "Epoch: 8, Batch: 87, Loss: 1.9311450719833374\n",
      "Epoch: 8, Batch: 88, Loss: 1.9304349422454834\n",
      "Epoch: 8, Batch: 88, Loss: 1.9304349422454834\n",
      "Epoch: 8, Batch: 89, Loss: 1.8967386484146118\n",
      "Epoch: 8, Batch: 89, Loss: 1.8967386484146118\n",
      "Epoch: 8, Batch: 90, Loss: 1.8879286050796509\n",
      "Epoch: 8, Batch: 90, Loss: 1.8879286050796509\n",
      "Epoch: 8, Batch: 91, Loss: 1.881438970565796\n",
      "Epoch: 8, Batch: 91, Loss: 1.881438970565796\n",
      "Epoch: 8, Batch: 92, Loss: 1.9361103773117065\n",
      "Epoch: 8, Batch: 92, Loss: 1.9361103773117065\n",
      "Epoch: 8, Batch: 93, Loss: 1.876747488975525\n",
      "Epoch: 8, Batch: 93, Loss: 1.876747488975525\n",
      "Epoch: 8, Batch: 94, Loss: 1.8785490989685059\n",
      "Epoch: 8, Batch: 94, Loss: 1.8785490989685059\n",
      "Epoch: 8, Batch: 95, Loss: 1.8986876010894775\n",
      "Epoch: 8, Batch: 95, Loss: 1.8986876010894775\n",
      "Epoch: 8, Batch: 96, Loss: 1.8902820348739624\n",
      "Epoch: 8, Batch: 96, Loss: 1.8902820348739624\n",
      "Epoch: 8, Batch: 97, Loss: 1.913541316986084\n",
      "Epoch: 8, Batch: 97, Loss: 1.913541316986084\n",
      "Epoch: 8, Batch: 98, Loss: 1.8291711807250977\n",
      "Epoch: 8, Batch: 98, Loss: 1.8291711807250977\n",
      "Epoch: 8, Batch: 99, Loss: 1.8749860525131226\n",
      "Epoch: 8, Batch: 99, Loss: 1.8749860525131226\n",
      "Generated text: \u0000y?\n",
      "\n",
      "BENVOLIO:\n",
      "I thank, that so word: go, nursel be not?\n",
      "\n",
      "VOLUMNIA:\n",
      "Speaks, seir, Come, I they, belber Julie, for\n",
      "let out-call th...\n",
      "Generated text: \u0000y?\n",
      "\n",
      "BENVOLIO:\n",
      "I thank, that so word: go, nursel be not?\n",
      "\n",
      "VOLUMNIA:\n",
      "Speaks, seir, Come, I they, belber Julie, for\n",
      "let out-call th...\n",
      "Epoch: 9, Batch: 0, Loss: 1.8794569969177246\n",
      "Epoch: 9, Batch: 0, Loss: 1.8794569969177246\n",
      "Epoch: 9, Batch: 1, Loss: 1.8854053020477295\n",
      "Epoch: 9, Batch: 1, Loss: 1.8854053020477295\n",
      "Epoch: 9, Batch: 2, Loss: 1.924069881439209\n",
      "Epoch: 9, Batch: 2, Loss: 1.924069881439209\n",
      "Epoch: 9, Batch: 3, Loss: 1.9644218683242798\n",
      "Epoch: 9, Batch: 3, Loss: 1.9644218683242798\n",
      "Epoch: 9, Batch: 4, Loss: 1.903228998184204\n",
      "Epoch: 9, Batch: 4, Loss: 1.903228998184204\n",
      "Epoch: 9, Batch: 5, Loss: 1.9640328884124756\n",
      "Epoch: 9, Batch: 5, Loss: 1.9640328884124756\n",
      "Epoch: 9, Batch: 6, Loss: 1.926201343536377\n",
      "Epoch: 9, Batch: 6, Loss: 1.926201343536377\n",
      "Epoch: 9, Batch: 7, Loss: 1.925380825996399\n",
      "Epoch: 9, Batch: 7, Loss: 1.925380825996399\n",
      "Epoch: 9, Batch: 8, Loss: 1.9029736518859863\n",
      "Epoch: 9, Batch: 8, Loss: 1.9029736518859863\n",
      "Epoch: 9, Batch: 9, Loss: 1.8639569282531738\n",
      "Epoch: 9, Batch: 9, Loss: 1.8639569282531738\n",
      "Epoch: 9, Batch: 10, Loss: 1.854804515838623\n",
      "Epoch: 9, Batch: 10, Loss: 1.854804515838623\n",
      "Epoch: 9, Batch: 11, Loss: 1.9088784456253052\n",
      "Epoch: 9, Batch: 11, Loss: 1.9088784456253052\n",
      "Epoch: 9, Batch: 12, Loss: 1.9023537635803223\n",
      "Epoch: 9, Batch: 12, Loss: 1.9023537635803223\n",
      "Epoch: 9, Batch: 13, Loss: 1.8912627696990967\n",
      "Epoch: 9, Batch: 13, Loss: 1.8912627696990967\n",
      "Epoch: 9, Batch: 14, Loss: 1.8580858707427979\n",
      "Epoch: 9, Batch: 14, Loss: 1.8580858707427979\n",
      "Epoch: 9, Batch: 15, Loss: 1.8666712045669556\n",
      "Epoch: 9, Batch: 15, Loss: 1.8666712045669556\n",
      "Epoch: 9, Batch: 16, Loss: 1.8620132207870483\n",
      "Epoch: 9, Batch: 16, Loss: 1.8620132207870483\n",
      "Epoch: 9, Batch: 17, Loss: 1.8641128540039062\n",
      "Epoch: 9, Batch: 17, Loss: 1.8641128540039062\n",
      "Epoch: 9, Batch: 18, Loss: 1.8544700145721436\n",
      "Epoch: 9, Batch: 18, Loss: 1.8544700145721436\n",
      "Epoch: 9, Batch: 19, Loss: 1.8670873641967773\n",
      "Epoch: 9, Batch: 19, Loss: 1.8670873641967773\n",
      "Epoch: 9, Batch: 20, Loss: 1.864924430847168\n",
      "Epoch: 9, Batch: 20, Loss: 1.864924430847168\n",
      "Epoch: 9, Batch: 21, Loss: 1.861778736114502\n",
      "Epoch: 9, Batch: 21, Loss: 1.861778736114502\n",
      "Epoch: 9, Batch: 22, Loss: 1.8937740325927734\n",
      "Epoch: 9, Batch: 22, Loss: 1.8937740325927734\n",
      "Epoch: 9, Batch: 23, Loss: 1.9337674379348755\n",
      "Epoch: 9, Batch: 23, Loss: 1.9337674379348755\n",
      "Epoch: 9, Batch: 24, Loss: 1.9020609855651855\n",
      "Epoch: 9, Batch: 24, Loss: 1.9020609855651855\n",
      "Epoch: 9, Batch: 25, Loss: 1.8543109893798828\n",
      "Epoch: 9, Batch: 25, Loss: 1.8543109893798828\n",
      "Epoch: 9, Batch: 26, Loss: 1.9194459915161133\n",
      "Epoch: 9, Batch: 26, Loss: 1.9194459915161133\n",
      "Epoch: 9, Batch: 27, Loss: 1.8897135257720947\n",
      "Epoch: 9, Batch: 27, Loss: 1.8897135257720947\n",
      "Epoch: 9, Batch: 28, Loss: 1.905685305595398\n",
      "Epoch: 9, Batch: 28, Loss: 1.905685305595398\n",
      "Epoch: 9, Batch: 29, Loss: 1.8878902196884155\n",
      "Epoch: 9, Batch: 29, Loss: 1.8878902196884155\n",
      "Epoch: 9, Batch: 30, Loss: 1.8697876930236816\n",
      "Epoch: 9, Batch: 30, Loss: 1.8697876930236816\n",
      "Epoch: 9, Batch: 31, Loss: 1.8684606552124023\n",
      "Epoch: 9, Batch: 31, Loss: 1.8684606552124023\n",
      "Epoch: 9, Batch: 32, Loss: 1.8388422727584839\n",
      "Epoch: 9, Batch: 32, Loss: 1.8388422727584839\n",
      "Epoch: 9, Batch: 33, Loss: 1.8989057540893555\n",
      "Epoch: 9, Batch: 33, Loss: 1.8989057540893555\n",
      "Epoch: 9, Batch: 34, Loss: 1.8670272827148438\n",
      "Epoch: 9, Batch: 34, Loss: 1.8670272827148438\n",
      "Epoch: 9, Batch: 35, Loss: 1.866128921508789\n",
      "Epoch: 9, Batch: 35, Loss: 1.866128921508789\n",
      "Epoch: 9, Batch: 36, Loss: 1.856435775756836\n",
      "Epoch: 9, Batch: 36, Loss: 1.856435775756836\n",
      "Epoch: 9, Batch: 37, Loss: 1.8591035604476929\n",
      "Epoch: 9, Batch: 37, Loss: 1.8591035604476929\n",
      "Epoch: 9, Batch: 38, Loss: 1.8401139974594116\n",
      "Epoch: 9, Batch: 38, Loss: 1.8401139974594116\n",
      "Epoch: 9, Batch: 39, Loss: 1.8374762535095215\n",
      "Epoch: 9, Batch: 39, Loss: 1.8374762535095215\n",
      "Epoch: 9, Batch: 40, Loss: 1.8245468139648438\n",
      "Epoch: 9, Batch: 40, Loss: 1.8245468139648438\n",
      "Epoch: 9, Batch: 41, Loss: 1.8938626050949097\n",
      "Epoch: 9, Batch: 41, Loss: 1.8938626050949097\n",
      "Epoch: 9, Batch: 42, Loss: 1.8440501689910889\n",
      "Epoch: 9, Batch: 42, Loss: 1.8440501689910889\n",
      "Epoch: 9, Batch: 43, Loss: 1.8991526365280151\n",
      "Epoch: 9, Batch: 43, Loss: 1.8991526365280151\n",
      "Epoch: 9, Batch: 44, Loss: 1.9089162349700928\n",
      "Epoch: 9, Batch: 44, Loss: 1.9089162349700928\n",
      "Epoch: 9, Batch: 45, Loss: 1.8908007144927979\n",
      "Epoch: 9, Batch: 45, Loss: 1.8908007144927979\n",
      "Epoch: 9, Batch: 46, Loss: 1.820968508720398\n",
      "Epoch: 9, Batch: 46, Loss: 1.820968508720398\n",
      "Epoch: 9, Batch: 47, Loss: 1.905044674873352\n",
      "Epoch: 9, Batch: 47, Loss: 1.905044674873352\n",
      "Epoch: 9, Batch: 48, Loss: 1.8201055526733398\n",
      "Epoch: 9, Batch: 48, Loss: 1.8201055526733398\n",
      "Epoch: 9, Batch: 49, Loss: 1.8768481016159058\n",
      "Epoch: 9, Batch: 49, Loss: 1.8768481016159058\n",
      "Epoch: 9, Batch: 50, Loss: 1.87754487991333\n",
      "Epoch: 9, Batch: 50, Loss: 1.87754487991333\n",
      "Epoch: 9, Batch: 51, Loss: 1.866100788116455\n",
      "Epoch: 9, Batch: 51, Loss: 1.866100788116455\n",
      "Epoch: 9, Batch: 52, Loss: 1.8208476305007935\n",
      "Epoch: 9, Batch: 52, Loss: 1.8208476305007935\n",
      "Epoch: 9, Batch: 53, Loss: 1.8620655536651611\n",
      "Epoch: 9, Batch: 53, Loss: 1.8620655536651611\n",
      "Epoch: 9, Batch: 54, Loss: 1.8474977016448975\n",
      "Epoch: 9, Batch: 54, Loss: 1.8474977016448975\n",
      "Epoch: 9, Batch: 55, Loss: 1.7958639860153198\n",
      "Epoch: 9, Batch: 55, Loss: 1.7958639860153198\n",
      "Epoch: 9, Batch: 56, Loss: 1.837576150894165\n",
      "Epoch: 9, Batch: 56, Loss: 1.837576150894165\n",
      "Epoch: 9, Batch: 57, Loss: 1.8334293365478516\n",
      "Epoch: 9, Batch: 57, Loss: 1.8334293365478516\n",
      "Epoch: 9, Batch: 58, Loss: 1.8315341472625732\n",
      "Epoch: 9, Batch: 58, Loss: 1.8315341472625732\n",
      "Epoch: 9, Batch: 59, Loss: 1.8024609088897705\n",
      "Epoch: 9, Batch: 59, Loss: 1.8024609088897705\n",
      "Epoch: 9, Batch: 60, Loss: 1.8718299865722656\n",
      "Epoch: 9, Batch: 60, Loss: 1.8718299865722656\n",
      "Epoch: 9, Batch: 61, Loss: 1.8702263832092285\n",
      "Epoch: 9, Batch: 61, Loss: 1.8702263832092285\n",
      "Epoch: 9, Batch: 62, Loss: 1.901283860206604\n",
      "Epoch: 9, Batch: 62, Loss: 1.901283860206604\n",
      "Epoch: 9, Batch: 63, Loss: 1.8592580556869507\n",
      "Epoch: 9, Batch: 63, Loss: 1.8592580556869507\n",
      "Epoch: 9, Batch: 64, Loss: 1.8530222177505493\n",
      "Epoch: 9, Batch: 64, Loss: 1.8530222177505493\n",
      "Epoch: 9, Batch: 65, Loss: 1.873917579650879\n",
      "Epoch: 9, Batch: 65, Loss: 1.873917579650879\n",
      "Epoch: 9, Batch: 66, Loss: 1.8672614097595215\n",
      "Epoch: 9, Batch: 66, Loss: 1.8672614097595215\n",
      "Epoch: 9, Batch: 67, Loss: 1.8690797090530396\n",
      "Epoch: 9, Batch: 67, Loss: 1.8690797090530396\n",
      "Epoch: 9, Batch: 68, Loss: 1.8466193675994873\n",
      "Epoch: 9, Batch: 68, Loss: 1.8466193675994873\n",
      "Epoch: 9, Batch: 69, Loss: 1.8644027709960938\n",
      "Epoch: 9, Batch: 69, Loss: 1.8644027709960938\n",
      "Epoch: 9, Batch: 70, Loss: 1.8690061569213867\n",
      "Epoch: 9, Batch: 70, Loss: 1.8690061569213867\n",
      "Epoch: 9, Batch: 71, Loss: 1.789119005203247\n",
      "Epoch: 9, Batch: 71, Loss: 1.789119005203247\n",
      "Epoch: 9, Batch: 72, Loss: 1.848549723625183\n",
      "Epoch: 9, Batch: 72, Loss: 1.848549723625183\n",
      "Epoch: 9, Batch: 73, Loss: 1.8340888023376465\n",
      "Epoch: 9, Batch: 73, Loss: 1.8340888023376465\n",
      "Epoch: 9, Batch: 74, Loss: 1.835477590560913\n",
      "Epoch: 9, Batch: 74, Loss: 1.835477590560913\n",
      "Epoch: 9, Batch: 75, Loss: 1.827684998512268\n",
      "Epoch: 9, Batch: 75, Loss: 1.827684998512268\n",
      "Epoch: 9, Batch: 76, Loss: 1.7693674564361572\n",
      "Epoch: 9, Batch: 76, Loss: 1.7693674564361572\n",
      "Epoch: 9, Batch: 77, Loss: 1.8078651428222656\n",
      "Epoch: 9, Batch: 77, Loss: 1.8078651428222656\n",
      "Epoch: 9, Batch: 78, Loss: 1.8416731357574463\n",
      "Epoch: 9, Batch: 78, Loss: 1.8416731357574463\n",
      "Epoch: 9, Batch: 79, Loss: 1.8434947729110718\n",
      "Epoch: 9, Batch: 79, Loss: 1.8434947729110718\n",
      "Epoch: 9, Batch: 80, Loss: 1.8340281248092651\n",
      "Epoch: 9, Batch: 80, Loss: 1.8340281248092651\n",
      "Epoch: 9, Batch: 81, Loss: 1.8529181480407715\n",
      "Epoch: 9, Batch: 81, Loss: 1.8529181480407715\n",
      "Epoch: 9, Batch: 82, Loss: 1.9381638765335083\n",
      "Epoch: 9, Batch: 82, Loss: 1.9381638765335083\n",
      "Epoch: 9, Batch: 83, Loss: 1.8546786308288574\n",
      "Epoch: 9, Batch: 83, Loss: 1.8546786308288574\n",
      "Epoch: 9, Batch: 84, Loss: 1.866111159324646\n",
      "Epoch: 9, Batch: 84, Loss: 1.866111159324646\n",
      "Epoch: 9, Batch: 85, Loss: 1.8432600498199463\n",
      "Epoch: 9, Batch: 85, Loss: 1.8432600498199463\n",
      "Epoch: 9, Batch: 86, Loss: 1.8522779941558838\n",
      "Epoch: 9, Batch: 86, Loss: 1.8522779941558838\n",
      "Epoch: 9, Batch: 87, Loss: 1.8429561853408813\n",
      "Epoch: 9, Batch: 87, Loss: 1.8429561853408813\n",
      "Epoch: 9, Batch: 88, Loss: 1.8301925659179688\n",
      "Epoch: 9, Batch: 88, Loss: 1.8301925659179688\n",
      "Epoch: 9, Batch: 89, Loss: 1.8521273136138916\n",
      "Epoch: 9, Batch: 89, Loss: 1.8521273136138916\n",
      "Epoch: 9, Batch: 90, Loss: 1.8559867143630981\n",
      "Epoch: 9, Batch: 90, Loss: 1.8559867143630981\n",
      "Epoch: 9, Batch: 91, Loss: 1.8848891258239746\n",
      "Epoch: 9, Batch: 91, Loss: 1.8848891258239746\n",
      "Epoch: 9, Batch: 92, Loss: 1.8165862560272217\n",
      "Epoch: 9, Batch: 92, Loss: 1.8165862560272217\n",
      "Epoch: 9, Batch: 93, Loss: 1.8067774772644043\n",
      "Epoch: 9, Batch: 93, Loss: 1.8067774772644043\n",
      "Epoch: 9, Batch: 94, Loss: 1.828468918800354\n",
      "Epoch: 9, Batch: 94, Loss: 1.828468918800354\n",
      "Epoch: 9, Batch: 95, Loss: 1.7920520305633545\n",
      "Epoch: 9, Batch: 95, Loss: 1.7920520305633545\n",
      "Epoch: 9, Batch: 96, Loss: 1.7828805446624756\n",
      "Epoch: 9, Batch: 96, Loss: 1.7828805446624756\n",
      "Epoch: 9, Batch: 97, Loss: 1.8549152612686157\n",
      "Epoch: 9, Batch: 97, Loss: 1.8549152612686157\n",
      "Epoch: 9, Batch: 98, Loss: 1.8078221082687378\n",
      "Epoch: 9, Batch: 98, Loss: 1.8078221082687378\n",
      "Epoch: 9, Batch: 99, Loss: 1.8550820350646973\n",
      "Epoch: 9, Batch: 99, Loss: 1.8550820350646973\n",
      "Generated text: \u0000t thou read,\n",
      "For what confult you loudged little on,\n",
      "To roised me to live your make of Frey wich\n",
      "Are to consument o'er mother; an...\n",
      "Generated text: \u0000t thou read,\n",
      "For what confult you loudged little on,\n",
      "To roised me to live your make of Frey wich\n",
      "Are to consument o'er mother; an...\n"
     ]
    }
   ],
   "source": [
    "n_batches = len(bpe_data)//batch_size\n",
    "n_epochs = 10\n",
    "seq_len = 100\n",
    "\n",
    "losses = {}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch in range(100):\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        train_x, train_y = get_data('train', device='cuda', use_bpe=True)\n",
    "        loss, logits = model.forward(train_x, train_y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        print(f'Epoch: {epoch}, Batch: {batch}, Loss: {loss}')\n",
    "        losses[epoch] = losses.get(epoch, []) + [loss.item()]\n",
    "    \n",
    "    # Generate text using BPE decoder\n",
    "    generated_ids = model.generate(idx=torch.zeros((1, 1), dtype=torch.long).cuda(), seq_len=100)[0].tolist()\n",
    "    generated_text = decode_bpe(generated_ids)\n",
    "    print(f\"Generated text: {generated_text[:200]}...\")  # Show first 200 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f15ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000OPEPSONERLE:\n",
      "Ay, what she we will the would Warwick;\n",
      "Maday, capter'd to shall from be aunded how,\n",
      "Fail drun no black to addvicts,\n",
      "And now one born Catiol dispation,\n",
      "Would she Is done thy like agbod\n",
      "Mearten opinacly gapers.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Call with is breasing to usurp, inderise.\n",
      "\n",
      "JULIET:\n",
      "You shall I long.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "A riclander; as him good, and the selff;\n",
      "Were must one ve: proced is triquest.\n",
      "He must to be dearth me dream traibleer\n",
      "His came to admend, and for what with dok-morrow\n",
      "Do the love and bear-destravam stabs.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "On, my lord, my lord from now; brother, in the soul any mole\n",
      "Yet would \n"
     ]
    }
   ],
   "source": [
    "# Generate longer text with BPE\n",
    "generated_ids = model.generate(idx=torch.zeros((1, 1), dtype=torch.long).cuda(), seq_len=500)[0].tolist()\n",
    "generated_text = decode_bpe(generated_ids)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minichat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
